{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13811294,"sourceType":"datasetVersion","datasetId":8794300},{"sourceId":13894314,"sourceType":"datasetVersion","datasetId":8852034},{"sourceId":2530487,"sourceType":"datasetVersion","datasetId":1533360}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# =============================================================================\n# FULL SCRIPT (UPDATED FIX): MobileNetV3-Large backbone + Mixup DG\n# Fixes the runtime error by using the correct MobileNetV3 feature dim (960).\n# =============================================================================\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom typing import Dict\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\n\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\nfrom sklearn.metrics import roc_auc_score, f1_score, roc_curve, average_precision_score\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# =============================================================================\n# (OPTIONAL) HARMONIZATION\n# =============================================================================\n\nRUN_HARMONIZATION = True  # set False if you already generated harmonized CSVs\n\n\ndef harmonize_odir(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/odir-clr/ODIR_CLR\"\n\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_ Set/train_images\"\n        label_file = f\"{base_path}/Training_ Set/train_annotation.xlsx\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Validation_set/val_images\"\n        label_file = f\"{base_path}/Validation_set/val_annotation.xlsx\"\n    else:\n        img_dir = f\"{base_path}/Test_Set/test_images\"\n        label_file = f\"{base_path}/Test_Set/test_annotation.xlsx\"\n\n    df = pd.read_excel(label_file)\n    label_cols = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n    harmonized_rows = []\n\n    for _, row in df.iterrows():\n        patient_id = row['ID']\n        labels = {col: int(row[col]) for col in label_cols}\n\n        if pd.notna(row['Left-Fundus']) and str(row['Left-Fundus']).strip():\n            left_path = os.path.join(img_dir, f\"{patient_id}_left.jpg\")\n            harmonized_rows.append({\n                'image_path': left_path,\n                'dataset': 'ODIR',\n                'split': split,\n                'ID': patient_id,\n                **labels\n            })\n\n        if pd.notna(row['Right-Fundus']) and str(row['Right-Fundus']).strip():\n            right_path = os.path.join(img_dir, f\"{patient_id}_right.jpg\")\n            harmonized_rows.append({\n                'image_path': right_path,\n                'dataset': 'ODIR',\n                'split': split,\n                'ID': patient_id,\n                **labels\n            })\n\n    return pd.DataFrame(harmonized_rows)\n\n\ndef harmonize_rfmid_v1(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/retinal-disease-classification\"\n\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_Set/Training_Set/Training\"\n        label_file = f\"{base_path}/Training_Set/Training_Set/RFMiD_Training_Labels.csv\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Evaluation_Set/Evaluation_Set/Validation\"\n        label_file = f\"{base_path}/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv\"\n    else:\n        img_dir = f\"{base_path}/Test_Set/Test_Set/Test\"\n        label_file = f\"{base_path}/Test_Set/Test_Set/RFMiD_Testing_Labels.csv\"\n\n    df = pd.read_csv(label_file)\n\n    all_disease_cols = ['DR', 'ARMD', 'MH', 'DN', 'MYA', 'BRVO', 'TSLN',\n                        'ERM', 'LS', 'MS', 'CSR', 'ODC', 'CRVO', 'TV', 'AH',\n                        'ODP', 'ODE', 'ST', 'AION', 'PT', 'RT', 'RS', 'CRS',\n                        'EDN', 'RPEC', 'MHL', 'RP', 'CWS', 'CB', 'ODPM',\n                        'PRH', 'MNF', 'HR', 'CRAO', 'TD', 'CME', 'PTCR', 'CF',\n                        'VH', 'MCA', 'VS', 'BRAO', 'PLQ', 'HPED', 'CL']\n\n    harmonized_rows = []\n\n    for _, row in df.iterrows():\n        image_id = row['ID']\n        image_path = None\n        for ext in ['.png', '.jpg', '.jpeg']:\n            candidate = os.path.join(img_dir, f\"{image_id}{ext}\")\n            if os.path.exists(candidate):\n                image_path = candidate\n                break\n        if image_path is None:\n            image_path = os.path.join(img_dir, str(image_id))\n\n        # Mapping to 8-label schema: N,D,G,C,A,H,M,O\n        N = 1 if row['Disease_Risk'] == 0 else 0\n        D = 1 if row.get('DR', 0) == 1 else 0\n        G = 1 if row.get('ODC', 0) == 1 else 0\n        C = 1 if row.get('MH', 0) == 1 else 0\n        A = 1 if row.get('ARMD', 0) == 1 else 0\n        H = 1 if row.get('HR', 0) == 1 else 0\n        M = 1 if row.get('MYA', 0) == 1 else 0\n\n        used_for_mapping = ['DR', 'ODC', 'MH', 'ARMD', 'HR', 'MYA']\n        other_cols = [col for col in all_disease_cols if col not in used_for_mapping]\n        O = 1 if any(row.get(col, 0) == 1 for col in other_cols) else 0\n\n        harmonized_rows.append({\n            'image_path': image_path,\n            'dataset': 'RFMiD_v1',\n            'split': split,\n            'ID': image_id,\n            'N': N, 'D': D, 'G': G, 'C': C, 'A': A, 'H': H, 'M': M, 'O': O\n        })\n\n    return pd.DataFrame(harmonized_rows)\n\n\ndef harmonize_rfmid_v2(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/rdc-version-2/RFDiM2_0\"\n\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_set_2/Train_2\"\n        label_file = f\"{base_path}/Training_set_2/RFMiD_2_Training_labels.csv\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Validation_set_2/Validation_2\"\n        label_file = f\"{base_path}/Validation_set_2/RFMiD_2_Validation_labels.csv\"\n    else:\n        img_dir = f\"{base_path}/Test_set_2/Test_2\"\n        label_file = f\"{base_path}/Test_set_2/RFMiD_2_Testing_labels.csv\"\n\n    try:\n        df = pd.read_csv(label_file, encoding='utf-8')\n    except UnicodeDecodeError:\n        df = pd.read_csv(label_file, encoding='latin1')\n\n    df.columns = df.columns.str.strip()\n\n    potential_disease_cols = ['AH', 'AION', 'ARMD', 'BRVO', 'CB', 'CF', 'CL', 'CME',\n                              'CNV', 'CRAO', 'CRS', 'CRVO', 'CSR', 'CWS', 'CSC', 'DN',\n                              'DR', 'EDN', 'ERM', 'GRT', 'HPED', 'HR', 'LS', 'MCA',\n                              'ME', 'MH', 'MHL', 'MS', 'MYA', 'ODC', 'ODE', 'ODP',\n                              'ON', 'OPDM', 'PRH', 'RD', 'RHL', 'RTR', 'RP', 'RPEC',\n                              'RS', 'RT', 'SOFE', 'ST', 'TD', 'TSLN', 'TV', 'VS',\n                              'HTN', 'IIH']\n\n    all_disease_cols = [col for col in potential_disease_cols if col in df.columns]\n    harmonized_rows = []\n\n    skipped_count = 0\n    found_count = 0\n\n    for _, row in df.iterrows():\n        image_id = int(row['ID'])\n\n        image_path = None\n        for ext in ['.jpg', '.JPG', '.png', '.PNG', '.jpeg', '.JPEG']:\n            candidate = os.path.join(img_dir, f\"{image_id}{ext}\")\n            if os.path.exists(candidate):\n                image_path = candidate\n                found_count += 1\n                break\n\n        if image_path is None:\n            skipped_count += 1\n            continue\n\n        # v2 uses WNL for Normal\n        wnl = row.get('WNL', 0)\n        N = 1 if wnl == 1 else 0\n        D = 1 if row.get('DR', 0) == 1 else 0\n        G = 1 if row.get('ODC', 0) == 1 else 0\n        C = 1 if row.get('MH', 0) == 1 else 0\n        A = 1 if row.get('ARMD', 0) == 1 else 0\n\n        # H: HTN preferred, else HR fallback\n        H = 1 if row.get('HTN', 0) == 1 else 0\n        if H == 0 and 'HR' in df.columns:\n            H = 1 if row.get('HR', 0) == 1 else 0\n\n        M = 1 if row.get('MYA', 0) == 1 else 0\n\n        used_for_mapping = ['DR', 'ODC', 'MH', 'ARMD', 'HTN', 'HR', 'MYA', 'WNL']\n        other_cols = [col for col in all_disease_cols if col not in used_for_mapping]\n        O = 1 if any(row.get(col, 0) == 1 for col in other_cols) else 0\n\n        harmonized_rows.append({\n            'image_path': image_path,\n            'dataset': 'RFMiD_v2',\n            'split': split,\n            'ID': image_id,\n            'N': N, 'D': D, 'G': G, 'C': C, 'A': A, 'H': H, 'M': M, 'O': O\n        })\n\n    if skipped_count > 0:\n        print(f\"RFMiD_v2 {split}: Found {found_count}, Skipped {skipped_count}\")\n\n    return pd.DataFrame(harmonized_rows)\n\n\ndef harmonize_all_datasets() -> Dict[str, pd.DataFrame]:\n    results = {}\n    print(\"\\n\" + \"=\"*60)\n    print(\"HARMONIZING DATASETS\")\n    print(\"=\"*60)\n\n    for split in ['train', 'val', 'test']:\n        print(f\"\\nProcessing {split} split...\")\n        results[f'ODIR_{split}'] = harmonize_odir(split)\n        results[f'RFMiD_v1_{split}'] = harmonize_rfmid_v1(split)\n        results[f'RFMiD_v2_{split}'] = harmonize_rfmid_v2(split)\n\n    return results\n\n\ndef print_statistics(harmonized_data: Dict[str, pd.DataFrame]):\n    label_cols = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"DATASET STATISTICS\")\n    print(\"=\"*60)\n\n    print(\"\\nðŸ“Š Sample Counts:\")\n    print(\"-\" * 40)\n    for key, df in sorted(harmonized_data.items()):\n        print(f\"{key:20s}: {len(df):5d} images\")\n\n    total_train = sum(len(df) for k, df in harmonized_data.items() if 'train' in k)\n    total_val = sum(len(df) for k, df in harmonized_data.items() if 'val' in k)\n    total_test = sum(len(df) for k, df in harmonized_data.items() if 'test' in k)\n\n    print(\"-\" * 40)\n    print(f\"{'Total Train':20s}: {total_train:5d} images\")\n    print(f\"{'Total Val':20s}: {total_val:5d} images\")\n    print(f\"{'Total Test':20s}: {total_test:5d} images\")\n    print(f\"{'Grand Total':20s}: {total_train + total_val + total_test:5d} images\")\n\n    for dataset_name in ['ODIR', 'RFMiD_v1', 'RFMiD_v2']:\n        dataset_dfs = {k: v for k, v in harmonized_data.items() if k.startswith(dataset_name)}\n        if not dataset_dfs:\n            continue\n\n        print(f\"\\n{'='*60}\")\n        print(f\"{dataset_name} Label Distribution\")\n        print(f\"{'='*60}\")\n\n        for split in ['train', 'val', 'test']:\n            key = f\"{dataset_name}_{split}\"\n            if key not in dataset_dfs:\n                continue\n\n            df = dataset_dfs[key]\n            print(f\"\\n{split.upper()} ({len(df)} images):\")\n            print(\"-\" * 40)\n            for col in label_cols:\n                count = int(df[col].sum())\n                pct = (count / len(df)) * 100 if len(df) > 0 else 0\n                print(f\"  {col}: {count:5d} ({pct:5.1f}%)\")\n\n\ndef save_harmonized_data(harmonized_data: Dict[str, pd.DataFrame], output_dir: str = './harmonized_labels'):\n    os.makedirs(output_dir, exist_ok=True)\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"SAVING HARMONIZED DATA\")\n    print(\"=\"*60)\n\n    for key, df in harmonized_data.items():\n        output_path = os.path.join(output_dir, f\"{key}.csv\")\n        df.to_csv(output_path, index=False)\n        print(f\"âœ… Saved {key:20s}: {len(df):5d} rows â†’ {output_path}\")\n\n    print(\"\\nðŸ“¦ Creating combined files...\")\n    for split in ['train', 'val', 'test']:\n        split_dfs = [v for k, v in harmonized_data.items() if k.endswith(f'_{split}')]\n        if split_dfs:\n            combined = pd.concat(split_dfs, ignore_index=True)\n            output_path = os.path.join(output_dir, f\"combined_{split}.csv\")\n            combined.to_csv(output_path, index=False)\n            print(f\"âœ… Saved combined_{split:5s}: {len(combined):5d} rows â†’ {output_path}\")\n\n    print(f\"\\nâœ¨ All files saved to: {output_dir}\")\n\n\ndef verify_images(harmonized_data: Dict[str, pd.DataFrame]):\n    print(\"\\n\" + \"=\"*60)\n    print(\"VERIFYING IMAGE PATHS\")\n    print(\"=\"*60)\n\n    all_good = True\n    for key, df in sorted(harmonized_data.items()):\n        missing = df[~df['image_path'].apply(os.path.exists)]\n        if len(missing) > 0:\n            print(f\"âŒ {key:20s}: {len(missing)} missing images\")\n            all_good = False\n        else:\n            print(f\"âœ… {key:20s}: All {len(df)} images found\")\n\n    if all_good:\n        print(\"\\nðŸŽ‰ All image paths verified successfully!\")\n    else:\n        print(\"\\nâš ï¸  Some images are missing - check the paths above\")\n\n\n# =============================================================================\n# CONFIG (LODO: Train=ODIR + RFMiD_v2, Test=RFMiD_v1)\n# =============================================================================\n\nSEED = 42\nSAVE_DIR = './results_lodo_mixup/fold_test_RFMiD_v1'\nTEST_DOMAIN = \"RFMiD_v1\"\nTRAIN_DOMAINS = \"ODIR + RFMiD_v2\"\nMIXUP_ALPHA = 0.2\n\nTEST_CSV = '/kaggle/working/harmonized_labels/RFMiD_v1_test.csv'\nTRAIN_CSVS = [\n    '/kaggle/working/harmonized_labels/ODIR_train.csv',\n    '/kaggle/working/harmonized_labels/RFMiD_v2_train.csv'\n]\nVAL_CSVS = [\n    '/kaggle/working/harmonized_labels/ODIR_val.csv',\n    '/kaggle/working/harmonized_labels/RFMiD_v2_val.csv'\n]\n\n# =============================================================================\n# REPRODUCIBILITY\n# =============================================================================\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n# =============================================================================\n# DATASET\n# =============================================================================\n\nclass RetinalDataset(Dataset):\n    def __init__(self, csv_path, domain_id, transform=None):\n        self.data = pd.read_csv(csv_path)\n        self.domain_id = domain_id\n        self.transform = transform\n        self.label_cols = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n\n        dup = self.data.duplicated(subset=[\"image_path\"], keep=\"first\").sum()\n        if dup > 0:\n            print(f\"[WARN] {dup} duplicates found, keeping first\")\n        self.data = self.data.drop_duplicates(subset=[\"image_path\"]).reset_index(drop=True)\n\n        valid_mask = self.data[\"image_path\"].apply(os.path.exists)\n        missing = (~valid_mask).sum()\n        if missing > 0:\n            print(f\"[WARN] Dropping {missing} missing images\")\n        self.data = self.data.loc[valid_mask].reset_index(drop=True)\n        print(f\"[INFO] Domain {domain_id}: Loaded {len(self.data)} valid images\")\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        try:\n            image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n        except Exception:\n            image = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n\n        labels = torch.tensor(row[self.label_cols].values.astype(\"float32\"))\n        if self.transform:\n            image = self.transform(image)\n\n        return image, labels, self.domain_id\n\n# =============================================================================\n# POSITIVE CLASS WEIGHTS\n# =============================================================================\n\ndef calculate_pos_weights(datasets, clip_min=0.5, clip_max=50.0):\n    all_labels = []\n    for ds in datasets:\n        all_labels.append(ds.data[[\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]].values)\n\n    combined = np.vstack(all_labels)\n    pos = combined.sum(axis=0)\n    neg = len(combined) - pos\n    raw = neg / (pos + 1e-5)\n    clipped = np.clip(raw, clip_min, clip_max)\n\n    print(\"\\n[INFO] Positive class weights (from training domains):\")\n    for i, col in enumerate([\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]):\n        print(f\"  {col}: {clipped[i]:.2f}\")\n\n    return torch.tensor(clipped, dtype=torch.float32)\n\n# =============================================================================\n# MODEL (MobileNetV3-Large) - FIXED FEATURE DIM\n# =============================================================================\n\nclass MixupMultiLabel(nn.Module):\n    \"\"\"\n    MobileNetV3-Large backbone + custom head.\n    IMPORTANT FIX:\n      - If we set backbone.classifier = Identity, backbone(x) returns 960-d features (not 1280).\n      - So in_features must be 960 (classifier[0].in_features), not classifier[-1].in_features.\n    \"\"\"\n    def __init__(self, num_classes=8, dropout=0.3):\n        super().__init__()\n\n        # weights enum varies by torchvision version; keep it robust\n        try:\n            weights = models.MobileNet_V3_Large_Weights.IMAGENET1K_V2\n        except Exception:\n            weights = models.MobileNet_V3_Large_Weights.DEFAULT\n\n        self.backbone = models.mobilenet_v3_large(weights=weights)\n\n        # classifier[0] is Linear(960 -> 1280) in torchvision MobileNetV3-Large\n        in_features = self.backbone.classifier[0].in_features  # <-- FIX (should be 960)\n\n        # remove original classifier so forward returns 960-d features\n        self.backbone.classifier = nn.Identity()\n\n        self.classifier = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(in_features, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(dropout),\n            nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x):\n        feats = self.backbone(x)        # [B, 960]\n        logits = self.classifier(feats) # [B, 8]\n        return logits\n\n# =============================================================================\n# TRANSFORMS\n# =============================================================================\n\ndef get_transforms(is_train=False):\n    if is_train:\n        return transforms.Compose([\n            transforms.Resize((256, 256)),\n            transforms.RandomCrop(224),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n\n# =============================================================================\n# METRICS\n# =============================================================================\n\ndef compute_metrics(labels, probs, thresholds=None):\n    n_classes = labels.shape[1]\n\n    aucs = []\n    for i in range(n_classes):\n        if len(np.unique(labels[:, i])) > 1:\n            aucs.append(roc_auc_score(labels[:, i], probs[:, i]))\n        else:\n            aucs.append(np.nan)\n\n    aps = []\n    for i in range(n_classes):\n        if len(np.unique(labels[:, i])) > 1:\n            aps.append(average_precision_score(labels[:, i], probs[:, i]))\n        else:\n            aps.append(np.nan)\n\n    if thresholds is None:\n        thresholds = np.full(n_classes, 0.5)\n\n    preds = (probs >= thresholds).astype(int)\n    f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n\n    return {\n        \"mAUC\": float(np.nanmean(aucs)),\n        \"mAP\": float(np.nanmean(aps)),\n        \"per_class_auc\": aucs,\n        \"per_class_ap\": aps,\n        \"macro_f1\": float(f1),\n    }\n\ndef find_optimal_thresholds(labels, probs):\n    n_classes = labels.shape[1]\n    thresholds = []\n    search_range = np.linspace(0.05, 0.95, 91)\n\n    for i in range(n_classes):\n        best_f1, best_t = 0.0, 0.5\n        if len(np.unique(labels[:, i])) > 1:\n            for t in search_range:\n                preds = (probs[:, i] >= t).astype(int)\n                f1 = f1_score(labels[:, i], preds, zero_division=0)\n                if f1 > best_f1:\n                    best_f1, best_t = f1, t\n        thresholds.append(best_t)\n\n    return np.array(thresholds)\n\n# =============================================================================\n# MIXUP TRAINING\n# =============================================================================\n\ndef train_epoch_mixup(model, loaders_dict, criterion, optimizer, device, mixup_alpha=0.2):\n    model.train()\n    losses = []\n    mixup_stats = {'total_batches': 0, 'mixup_batches': 0}\n\n    domain_iters = {k: iter(v) for k, v in loaders_dict.items()}\n    domain_ids = list(loaders_dict.keys())\n    max_batches = max(len(loader) for loader in loaders_dict.values())\n\n    pbar = tqdm(range(max_batches), desc=\"Train (Mixup)\", leave=False)\n\n    for _ in pbar:\n        do_mixup = (len(domain_ids) >= 2) and (np.random.rand() > 0.5)\n\n        if do_mixup:\n            d1, d2 = np.random.choice(domain_ids, size=2, replace=False)\n\n            try:\n                imgs1, labels1, _ = next(domain_iters[d1])\n            except StopIteration:\n                domain_iters[d1] = iter(loaders_dict[d1])\n                imgs1, labels1, _ = next(domain_iters[d1])\n\n            try:\n                imgs2, labels2, _ = next(domain_iters[d2])\n            except StopIteration:\n                domain_iters[d2] = iter(loaders_dict[d2])\n                imgs2, labels2, _ = next(domain_iters[d2])\n\n            min_size = min(imgs1.size(0), imgs2.size(0))\n            imgs1, labels1 = imgs1[:min_size], labels1[:min_size]\n            imgs2, labels2 = imgs2[:min_size], labels2[:min_size]\n\n            lam = np.random.beta(mixup_alpha, mixup_alpha)\n\n            mixed_imgs = lam * imgs1 + (1 - lam) * imgs2\n            mixed_labels = lam * labels1 + (1 - lam) * labels2\n\n            mixed_imgs = mixed_imgs.to(device)\n            mixed_labels = mixed_labels.to(device)\n\n            optimizer.zero_grad()\n            logits = model(mixed_imgs)\n            loss = criterion(logits, mixed_labels)\n\n            mixup_stats['mixup_batches'] += 1\n\n        else:\n            d = int(np.random.choice(domain_ids))\n            try:\n                imgs, labels, _ = next(domain_iters[d])\n            except StopIteration:\n                domain_iters[d] = iter(loaders_dict[d])\n                imgs, labels, _ = next(domain_iters[d])\n\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            logits = model(imgs)\n            loss = criterion(logits, labels)\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        losses.append(loss.item())\n        mixup_stats['total_batches'] += 1\n        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n\n    return {\n        \"loss\": float(np.mean(losses)),\n        \"mixup_ratio\": mixup_stats['mixup_batches'] / max(1, mixup_stats['total_batches'])\n    }\n\n@torch.no_grad()\ndef validate(model, loader, criterion, device, thresholds=None):\n    model.eval()\n    losses, all_probs, all_labels = [], [], []\n\n    for batch in tqdm(loader, desc=\"Val\", leave=False):\n        if len(batch) == 3:\n            images, labels, _ = batch\n        else:\n            images, labels = batch\n\n        images, labels = images.to(device), labels.to(device)\n        logits = model(images)\n        loss = criterion(logits, labels)\n\n        losses.append(loss.item())\n        all_probs.append(torch.sigmoid(logits).cpu().numpy())\n        all_labels.append(labels.cpu().numpy())\n\n    probs = np.vstack(all_probs)\n    labels = np.vstack(all_labels)\n    metrics = compute_metrics(labels, probs, thresholds)\n    metrics[\"loss\"] = float(np.mean(losses))\n    return metrics, probs, labels\n\n# =============================================================================\n# PLOTS\n# =============================================================================\n\ndef plot_training_curves(history, save_dir):\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    epochs = range(1, len(history['train_loss']) + 1)\n\n    axes[0].plot(epochs, history['train_loss'], 'b-', linewidth=2, label='Train Loss', marker='o')\n    axes[0].plot(epochs, history['val_loss'], 'r-', linewidth=2, label='Val Loss', marker='s')\n    axes[0].set_xlabel('Epoch', fontsize=12)\n    axes[0].set_ylabel('Loss', fontsize=12)\n    axes[0].set_title('Training and Validation Loss (Mixup)', fontsize=13, fontweight='bold')\n    axes[0].legend(fontsize=11)\n    axes[0].grid(True, alpha=0.3)\n\n    axes[1].plot(epochs, history['val_auc'], 'r-', linewidth=2, label='Val mAUC', marker='s')\n    axes[1].set_xlabel('Epoch', fontsize=12)\n    axes[1].set_ylabel('mAUC', fontsize=12)\n    axes[1].set_title('Validation mAUC (Mixup)', fontsize=13, fontweight='bold')\n    axes[1].legend(fontsize=11)\n    axes[1].grid(True, alpha=0.3)\n    axes[1].set_ylim([0, 1.0])\n\n    plt.tight_layout()\n    plt.savefig(f'{save_dir}/training_curves.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"[INFO] âœ“ Saved training curves\")\n\ndef plot_per_class_roc(labels, probs, test_domain, save_dir):\n    class_names = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n    n_classes = 8\n\n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n    axes = axes.flatten()\n\n    for i in range(n_classes):\n        if len(np.unique(labels[:, i])) > 1:\n            fpr, tpr, _ = roc_curve(labels[:, i], probs[:, i])\n            auc = roc_auc_score(labels[:, i], probs[:, i])\n\n            axes[i].plot(fpr, tpr, linewidth=2, label=f'AUC = {auc:.3f}')\n            axes[i].plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5)\n            axes[i].set_xlabel('False Positive Rate', fontsize=10)\n            axes[i].set_ylabel('True Positive Rate', fontsize=10)\n            axes[i].set_title(f'Class {class_names[i]}', fontsize=11, fontweight='bold')\n            axes[i].legend(loc='lower right', fontsize=9)\n            axes[i].grid(True, alpha=0.3)\n        else:\n            axes[i].text(0.5, 0.5, 'Single class\\n(No ROC)', ha='center', va='center', fontsize=12)\n            axes[i].set_title(f'Class {class_names[i]}', fontsize=11, fontweight='bold')\n\n    plt.suptitle(f'Per-Class ROC Curves - Test on {test_domain} (Mixup)',\n                 fontsize=14, fontweight='bold', y=0.995)\n    plt.tight_layout()\n    plt.savefig(f'{save_dir}/per_class_roc_curves.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"[INFO] âœ“ Saved per-class ROC curves\")\n\ndef plot_macro_roc(labels, probs, test_domain, save_dir):\n    n_classes = 8\n    fig, ax = plt.subplots(figsize=(8, 6))\n\n    all_fpr, all_tpr = [], []\n    for i in range(n_classes):\n        if len(np.unique(labels[:, i])) > 1:\n            fpr, tpr, _ = roc_curve(labels[:, i], probs[:, i])\n            all_fpr.append(fpr)\n            all_tpr.append(tpr)\n\n    mean_fpr = np.linspace(0, 1, 100)\n    tprs = [np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(all_fpr, all_tpr)]\n    mean_tpr = np.mean(tprs, axis=0)\n    macro_auc = np.trapz(mean_tpr, mean_fpr)\n\n    ax.plot(mean_fpr, mean_tpr, linewidth=3,\n            label=f'Macro-avg ROC (AUC = {macro_auc:.3f})', color='#2ecc71')\n    ax.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.5, label='Random Classifier')\n    ax.set_xlabel('False Positive Rate', fontsize=12)\n    ax.set_ylabel('True Positive Rate', fontsize=12)\n    ax.set_title(f'Macro-Average ROC Curve - Test on {test_domain} (Mixup)',\n                 fontsize=13, fontweight='bold')\n    ax.legend(loc='lower right', fontsize=11)\n    ax.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig(f'{save_dir}/macro_roc_curve.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"[INFO] âœ“ Saved macro-average ROC curve\")\n\ndef plot_per_class_metrics(test_metrics, save_dir):\n    class_names = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n    aucs = test_metrics['per_class_auc']\n    aps = test_metrics['per_class_ap']\n\n    aucs = [auc if not np.isnan(auc) else 0 for auc in aucs]\n    aps = [ap if not np.isnan(ap) else 0 for ap in aps]\n\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    x = np.arange(len(class_names))\n\n    axes[0].bar(x, aucs, color='#3498db', alpha=0.8, edgecolor='black', linewidth=1.5)\n    axes[0].set_xlabel('Disease Class', fontsize=11)\n    axes[0].set_ylabel('AUC', fontsize=11)\n    axes[0].set_title('Per-Class AUC (Mixup)', fontsize=12, fontweight='bold')\n    axes[0].set_xticks(x)\n    axes[0].set_xticklabels(class_names)\n    axes[0].set_ylim([0, 1.0])\n    axes[0].grid(True, alpha=0.3, axis='y')\n    for i, auc in enumerate(aucs):\n        axes[0].text(i, auc + 0.02, f'{auc:.2f}', ha='center', fontsize=9)\n\n    axes[1].bar(x, aps, color='#2ecc71', alpha=0.8, edgecolor='black', linewidth=1.5)\n    axes[1].set_xlabel('Disease Class', fontsize=11)\n    axes[1].set_ylabel('Average Precision', fontsize=11)\n    axes[1].set_title('Per-Class Average Precision (Mixup)', fontsize=12, fontweight='bold')\n    axes[1].set_xticks(x)\n    axes[1].set_xticklabels(class_names)\n    axes[1].set_ylim([0, 1.0])\n    axes[1].grid(True, alpha=0.3, axis='y')\n    for i, ap in enumerate(aps):\n        axes[1].text(i, ap + 0.02, f'{ap:.2f}', ha='center', fontsize=9)\n\n    plt.tight_layout()\n    plt.savefig(f'{save_dir}/per_class_metrics.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"[INFO] âœ“ Saved per-class metrics chart\")\n\n# =============================================================================\n# MAIN\n# =============================================================================\n\nif __name__ == \"__main__\":\n    # Optional: harmonize + save CSVs\n    if RUN_HARMONIZATION:\n        harmonized_data = harmonize_all_datasets()\n        print_statistics(harmonized_data)\n        verify_images(harmonized_data)\n        save_harmonized_data(harmonized_data)\n\n    set_seed(SEED)\n    os.makedirs(SAVE_DIR, exist_ok=True)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    print(\"=\"*80)\n    print(f\"LODO FOLD (SWAPPED) with MIXUP DG: Test on {TEST_DOMAIN}\")\n    print(f\"Training on: {TRAIN_DOMAINS}\")\n    print(\"=\"*80)\n    print(f\"Device: {device}\")\n    print(f\"Seed: {SEED}\")\n    print(f\"Mixup Alpha: {MIXUP_ALPHA}\")\n    print(\"=\"*80)\n\n    # Load datasets\n    print(\"\\n[INFO] Loading datasets...\")\n    train_datasets = [RetinalDataset(csv, domain_id=i, transform=get_transforms(True))\n                      for i, csv in enumerate(TRAIN_CSVS)]\n    val_datasets = [RetinalDataset(csv, domain_id=i, transform=get_transforms(False))\n                    for i, csv in enumerate(VAL_CSVS)]\n    test_dataset = RetinalDataset(TEST_CSV, domain_id=999, transform=get_transforms(False))\n\n    print(f\"\\n[INFO] Total train: {sum(len(ds) for ds in train_datasets)} images\")\n    print(f\"[INFO] Total val: {sum(len(ds) for ds in val_datasets)} images\")\n    print(f\"[INFO] Test: {len(test_dataset)} images\")\n\n    # Pos weights from training domains only\n    pos_weights = calculate_pos_weights(train_datasets).to(device)\n\n    # DataLoaders\n    g = torch.Generator().manual_seed(SEED)\n    train_loaders = {\n        i: DataLoader(ds, batch_size=32, shuffle=True, num_workers=4,\n                      pin_memory=True, generator=g)\n        for i, ds in enumerate(train_datasets)\n    }\n\n    combined_val = ConcatDataset(val_datasets)\n    val_loader = DataLoader(combined_val, batch_size=32, shuffle=False,\n                            num_workers=4, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n                             num_workers=4, pin_memory=True)\n\n    # Model\n    print(\"\\n[INFO] Initializing MobileNetV3-Large Mixup model (FIXED)...\")\n    model = MixupMultiLabel().to(device)\n\n    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n\n    optimizer = optim.Adam([\n        {'params': model.backbone.parameters(), 'lr': 1e-4},\n        {'params': model.classifier.parameters(), 'lr': 1e-3}\n    ], weight_decay=1e-4)\n\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=3\n    )\n\n    history = {'train_loss': [], 'val_loss': [], 'val_auc': []}\n\n    # Train\n    best_val_auc, patience_counter = 0.0, 0\n    print(\"\\n[INFO] Training started with Mixup DG...\")\n    print(\"-\"*80)\n\n    for epoch in range(50):\n        train_metrics = train_epoch_mixup(\n            model, train_loaders, criterion, optimizer, device, mixup_alpha=MIXUP_ALPHA\n        )\n        val_metrics, _, _ = validate(model, val_loader, criterion, device)\n        scheduler.step(val_metrics['mAUC'])\n\n        history['train_loss'].append(train_metrics['loss'])\n        history['val_loss'].append(val_metrics['loss'])\n        history['val_auc'].append(val_metrics['mAUC'])\n\n        print(f\"Epoch {epoch+1:02d} | Train Loss: {train_metrics['loss']:.4f} \"\n              f\"| Val mAUC: {val_metrics['mAUC']:.4f} | Mixup: {train_metrics['mixup_ratio']:.1%}\")\n\n        if val_metrics['mAUC'] > best_val_auc:\n            best_val_auc = val_metrics['mAUC']\n            torch.save(model.state_dict(), f'{SAVE_DIR}/best_model.pth')\n            print(f\"  âœ“ Saved best model (val mAUC: {best_val_auc:.4f})\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n\n        if patience_counter >= 10:\n            print(f\"\\n[INFO] Early stopping at epoch {epoch+1}\")\n            break\n\n    # Load best\n    print(f\"\\n[INFO] Loading best model...\")\n    model.load_state_dict(torch.load(f'{SAVE_DIR}/best_model.pth', map_location=device))\n    print(f\"[INFO] Best validation mAUC: {best_val_auc:.4f}\")\n\n    # Thresholds on validation\n    print(f\"\\n[INFO] Finding optimal thresholds on validation...\")\n    _, val_probs, val_labels = validate(model, val_loader, criterion, device)\n    thresholds = find_optimal_thresholds(val_labels, val_probs)\n\n    class_names = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n    print(\"[INFO] Optimal thresholds:\")\n    for c, t in zip(class_names, thresholds):\n        print(f\"  {c}: {t:.3f}\")\n\n    # Test\n    print(f\"\\n[INFO] Testing on {TEST_DOMAIN}...\")\n    print(\"-\"*80)\n    test_metrics, test_probs, test_labels = validate(\n        model, test_loader, criterion, device, thresholds\n    )\n\n    print(\"\\n\" + \"=\"*80)\n    print(f\"TEST RESULTS - {TEST_DOMAIN} (Mixup DG)\")\n    print(\"=\"*80)\n    print(f\"mAUC:      {test_metrics['mAUC']:.4f}\")\n    print(f\"mAP:       {test_metrics['mAP']:.4f}\")\n    print(f\"Macro F1:  {test_metrics['macro_f1']:.4f}\")\n    print(\"=\"*80)\n\n    print(f\"\\n{'Class':<8} {'AUC':<10} {'AP':<10}\")\n    print(\"-\"*30)\n    for i, cls in enumerate(class_names):\n        auc = test_metrics['per_class_auc'][i]\n        ap = test_metrics['per_class_ap'][i]\n        auc_str = f\"{auc:.4f}\" if not np.isnan(auc) else \"N/A\"\n        ap_str = f\"{ap:.4f}\" if not np.isnan(ap) else \"N/A\"\n        print(f\"{cls:<8} {auc_str:<10} {ap_str:<10}\")\n    print(\"-\"*30)\n\n    # Save results\n    print(\"\\n[INFO] Saving results...\")\n    results_df = pd.DataFrame([{\n        'method': 'Mixup',\n        'backbone': 'mobilenet_v3_large',\n        'test_domain': TEST_DOMAIN,\n        'train_domains': TRAIN_DOMAINS,\n        'mAUC': test_metrics['mAUC'],\n        'mAP': test_metrics['mAP'],\n        'macro_f1': test_metrics['macro_f1'],\n        'best_val_auc': best_val_auc,\n        'mixup_alpha': MIXUP_ALPHA\n    }])\n    results_df.to_csv(f'{SAVE_DIR}/test_results.csv', index=False)\n    print(f\"[INFO] âœ“ Saved test_results.csv\")\n\n    # Visualizations\n    print(\"\\n[INFO] Generating visualizations...\")\n    plot_training_curves(history, SAVE_DIR)\n    plot_per_class_roc(test_labels, test_probs, TEST_DOMAIN, SAVE_DIR)\n    plot_macro_roc(test_labels, test_probs, TEST_DOMAIN, SAVE_DIR)\n    plot_per_class_metrics(test_metrics, SAVE_DIR)\n\n    print(\"\\n\" + \"=\"*80)\n    print(f\"âœ“ MIXUP LODO FOLD (SWAPPED) COMPLETE! (MobileNetV3-Large FIXED)\")\n    print(f\"âœ“ Results saved to: {SAVE_DIR}/\")\n    print(\"=\"*80)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-18T00:18:45.278216Z","iopub.execute_input":"2026-01-18T00:18:45.278520Z","iopub.status.idle":"2026-01-18T01:24:09.877156Z","shell.execute_reply.started":"2026-01-18T00:18:45.278493Z","shell.execute_reply":"2026-01-18T01:24:09.876390Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nHARMONIZING DATASETS\n============================================================\n\nProcessing train split...\nRFMiD_v2 train: Found 507, Skipped 2\n\nProcessing val split...\n\nProcessing test split...\nRFMiD_v2 test: Found 170, Skipped 4\n\n============================================================\nDATASET STATISTICS\n============================================================\n\nðŸ“Š Sample Counts:\n----------------------------------------\nODIR_test           :  2000 images\nODIR_train          :  7000 images\nODIR_val            :  1000 images\nRFMiD_v1_test       :   640 images\nRFMiD_v1_train      :  1920 images\nRFMiD_v1_val        :   640 images\nRFMiD_v2_test       :   170 images\nRFMiD_v2_train      :   507 images\nRFMiD_v2_val        :   177 images\n----------------------------------------\nTotal Train         :  9427 images\nTotal Val           :  1817 images\nTotal Test          :  2810 images\nGrand Total         : 14054 images\n\n============================================================\nODIR Label Distribution\n============================================================\n\nTRAIN (7000 images):\n----------------------------------------\n  N:  2280 ( 32.6%)\n  D:  2256 ( 32.2%)\n  G:   430 (  6.1%)\n  C:   424 (  6.1%)\n  A:   328 (  4.7%)\n  H:   206 (  2.9%)\n  M:   348 (  5.0%)\n  O:  1958 ( 28.0%)\n\nVAL (1000 images):\n----------------------------------------\n  N:   324 ( 32.4%)\n  D:   326 ( 32.6%)\n  G:    64 (  6.4%)\n  C:    62 (  6.2%)\n  A:    50 (  5.0%)\n  H:    32 (  3.2%)\n  M:    46 (  4.6%)\n  O:   272 ( 27.2%)\n\nTEST (2000 images):\n----------------------------------------\n  N:   648 ( 32.4%)\n  D:   654 ( 32.7%)\n  G:   116 (  5.8%)\n  C:   130 (  6.5%)\n  A:    98 (  4.9%)\n  H:    60 (  3.0%)\n  M:    92 (  4.6%)\n  O:   550 ( 27.5%)\n\n============================================================\nRFMiD_v1 Label Distribution\n============================================================\n\nTRAIN (1920 images):\n----------------------------------------\n  N:   401 ( 20.9%)\n  D:   376 ( 19.6%)\n  G:   282 ( 14.7%)\n  C:   317 ( 16.5%)\n  A:   100 (  5.2%)\n  H:     0 (  0.0%)\n  M:   101 (  5.3%)\n  O:   785 ( 40.9%)\n\nVAL (640 images):\n----------------------------------------\n  N:   134 ( 20.9%)\n  D:   132 ( 20.6%)\n  G:    72 ( 11.2%)\n  C:   102 ( 15.9%)\n  A:    38 (  5.9%)\n  H:     0 (  0.0%)\n  M:    34 (  5.3%)\n  O:   271 ( 42.3%)\n\nTEST (640 images):\n----------------------------------------\n  N:   134 ( 20.9%)\n  D:   124 ( 19.4%)\n  G:    91 ( 14.2%)\n  C:   104 ( 16.2%)\n  A:    31 (  4.8%)\n  H:     1 (  0.2%)\n  M:    32 (  5.0%)\n  O:   257 ( 40.2%)\n\n============================================================\nRFMiD_v2 Label Distribution\n============================================================\n\nTRAIN (507 images):\n----------------------------------------\n  N:   156 ( 30.8%)\n  D:    42 (  8.3%)\n  G:    21 (  4.1%)\n  C:    26 (  5.1%)\n  A:     5 (  1.0%)\n  H:    64 ( 12.6%)\n  M:    27 (  5.3%)\n  O:   256 ( 50.5%)\n\nVAL (177 images):\n----------------------------------------\n  N:    53 ( 29.9%)\n  D:    14 (  7.9%)\n  G:     9 (  5.1%)\n  C:     8 (  4.5%)\n  A:     3 (  1.7%)\n  H:    13 (  7.3%)\n  M:    11 (  6.2%)\n  O:    89 ( 50.3%)\n\nTEST (170 images):\n----------------------------------------\n  N:    52 ( 30.6%)\n  D:    14 (  8.2%)\n  G:     7 (  4.1%)\n  C:     7 (  4.1%)\n  A:     2 (  1.2%)\n  H:    18 ( 10.6%)\n  M:     5 (  2.9%)\n  O:    89 ( 52.4%)\n\n============================================================\nVERIFYING IMAGE PATHS\n============================================================\nâœ… ODIR_test           : All 2000 images found\nâœ… ODIR_train          : All 7000 images found\nâœ… ODIR_val            : All 1000 images found\nâœ… RFMiD_v1_test       : All 640 images found\nâœ… RFMiD_v1_train      : All 1920 images found\nâœ… RFMiD_v1_val        : All 640 images found\nâœ… RFMiD_v2_test       : All 170 images found\nâœ… RFMiD_v2_train      : All 507 images found\nâœ… RFMiD_v2_val        : All 177 images found\n\nðŸŽ‰ All image paths verified successfully!\n\n============================================================\nSAVING HARMONIZED DATA\n============================================================\nâœ… Saved ODIR_train          :  7000 rows â†’ ./harmonized_labels/ODIR_train.csv\nâœ… Saved RFMiD_v1_train      :  1920 rows â†’ ./harmonized_labels/RFMiD_v1_train.csv\nâœ… Saved RFMiD_v2_train      :   507 rows â†’ ./harmonized_labels/RFMiD_v2_train.csv\nâœ… Saved ODIR_val            :  1000 rows â†’ ./harmonized_labels/ODIR_val.csv\nâœ… Saved RFMiD_v1_val        :   640 rows â†’ ./harmonized_labels/RFMiD_v1_val.csv\nâœ… Saved RFMiD_v2_val        :   177 rows â†’ ./harmonized_labels/RFMiD_v2_val.csv\nâœ… Saved ODIR_test           :  2000 rows â†’ ./harmonized_labels/ODIR_test.csv\nâœ… Saved RFMiD_v1_test       :   640 rows â†’ ./harmonized_labels/RFMiD_v1_test.csv\nâœ… Saved RFMiD_v2_test       :   170 rows â†’ ./harmonized_labels/RFMiD_v2_test.csv\n\nðŸ“¦ Creating combined files...\nâœ… Saved combined_train:  9427 rows â†’ ./harmonized_labels/combined_train.csv\nâœ… Saved combined_val  :  1817 rows â†’ ./harmonized_labels/combined_val.csv\nâœ… Saved combined_test :  2810 rows â†’ ./harmonized_labels/combined_test.csv\n\nâœ¨ All files saved to: ./harmonized_labels\n================================================================================\nLODO FOLD (SWAPPED) with MIXUP DG: Test on RFMiD_v1\nTraining on: ODIR + RFMiD_v2\n================================================================================\nDevice: cuda\nSeed: 42\nMixup Alpha: 0.2\n================================================================================\n\n[INFO] Loading datasets...\n[INFO] Domain 0: Loaded 7000 valid images\n[INFO] Domain 1: Loaded 507 valid images\n[INFO] Domain 0: Loaded 1000 valid images\n[INFO] Domain 1: Loaded 177 valid images\n[INFO] Domain 999: Loaded 640 valid images\n\n[INFO] Total train: 7507 images\n[INFO] Total val: 1177 images\n[INFO] Test: 640 images\n\n[INFO] Positive class weights (from training domains):\n  N: 2.08\n  D: 2.27\n  G: 15.65\n  C: 15.68\n  A: 21.54\n  H: 26.80\n  M: 19.02\n  O: 2.39\n\n[INFO] Initializing MobileNetV3-Large Mixup model (FIXED)...\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.1M/21.1M [00:00<00:00, 123MB/s] \n","output_type":"stream"},{"name":"stdout","text":"\n[INFO] Training started with Mixup DG...\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | Train Loss: 0.8981 | Val mAUC: 0.7770 | Mixup: 53.9%\n  âœ“ Saved best model (val mAUC: 0.7770)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | Train Loss: 0.7058 | Val mAUC: 0.7722 | Mixup: 44.3%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | Train Loss: 0.6674 | Val mAUC: 0.7890 | Mixup: 51.6%\n  âœ“ Saved best model (val mAUC: 0.7890)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | Train Loss: 0.6749 | Val mAUC: 0.7961 | Mixup: 48.4%\n  âœ“ Saved best model (val mAUC: 0.7961)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | Train Loss: 0.6441 | Val mAUC: 0.7987 | Mixup: 50.2%\n  âœ“ Saved best model (val mAUC: 0.7987)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 06 | Train Loss: 0.6308 | Val mAUC: 0.8105 | Mixup: 46.6%\n  âœ“ Saved best model (val mAUC: 0.8105)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 07 | Train Loss: 0.5719 | Val mAUC: 0.8053 | Mixup: 53.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 08 | Train Loss: 0.5252 | Val mAUC: 0.8070 | Mixup: 46.6%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 09 | Train Loss: 0.5825 | Val mAUC: 0.8172 | Mixup: 52.1%\n  âœ“ Saved best model (val mAUC: 0.8172)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.4740 | Val mAUC: 0.8045 | Mixup: 52.5%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | Train Loss: 0.5115 | Val mAUC: 0.8183 | Mixup: 48.4%\n  âœ“ Saved best model (val mAUC: 0.8183)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | Train Loss: 0.5347 | Val mAUC: 0.8159 | Mixup: 51.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | Train Loss: 0.4386 | Val mAUC: 0.8197 | Mixup: 47.5%\n  âœ“ Saved best model (val mAUC: 0.8197)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | Train Loss: 0.4875 | Val mAUC: 0.8092 | Mixup: 52.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | Train Loss: 0.4414 | Val mAUC: 0.8059 | Mixup: 42.5%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 16 | Train Loss: 0.4754 | Val mAUC: 0.8046 | Mixup: 46.6%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 17 | Train Loss: 0.4680 | Val mAUC: 0.8094 | Mixup: 50.7%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 18 | Train Loss: 0.3953 | Val mAUC: 0.8102 | Mixup: 46.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 19 | Train Loss: 0.4202 | Val mAUC: 0.8109 | Mixup: 53.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 20 | Train Loss: 0.3522 | Val mAUC: 0.8130 | Mixup: 48.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 21 | Train Loss: 0.3832 | Val mAUC: 0.8125 | Mixup: 50.2%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 22 | Train Loss: 0.3968 | Val mAUC: 0.8148 | Mixup: 54.3%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23 | Train Loss: 0.3716 | Val mAUC: 0.8113 | Mixup: 54.3%\n\n[INFO] Early stopping at epoch 23\n\n[INFO] Loading best model...\n[INFO] Best validation mAUC: 0.8197\n\n[INFO] Finding optimal thresholds on validation...\n","output_type":"stream"},{"name":"stderr","text":"                                                    \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Optimal thresholds:\n  N: 0.640\n  D: 0.220\n  G: 0.460\n  C: 0.840\n  A: 0.690\n  H: 0.290\n  M: 0.790\n  O: 0.180\n\n[INFO] Testing on RFMiD_v1...\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nTEST RESULTS - RFMiD_v1 (Mixup DG)\n================================================================================\nmAUC:      0.8384\nmAP:       0.5037\nMacro F1:  0.4053\n================================================================================\n\nClass    AUC        AP        \n------------------------------\nN        0.9296     0.7354    \nD        0.8880     0.6530    \nG        0.7009     0.3660    \nC        0.8785     0.6806    \nA        0.8695     0.3952    \nH        0.8153     0.0084    \nM        0.9748     0.6513    \nO        0.6509     0.5392    \n------------------------------\n\n[INFO] Saving results...\n[INFO] âœ“ Saved test_results.csv\n\n[INFO] Generating visualizations...\n[INFO] âœ“ Saved training curves\n[INFO] âœ“ Saved per-class ROC curves\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/4249279455.py:705: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n  macro_auc = np.trapz(mean_tpr, mean_fpr)\n","output_type":"stream"},{"name":"stdout","text":"[INFO] âœ“ Saved macro-average ROC curve\n[INFO] âœ“ Saved per-class metrics chart\n\n================================================================================\nâœ“ MIXUP LODO FOLD (SWAPPED) COMPLETE! (MobileNetV3-Large FIXED)\nâœ“ Results saved to: ./results_lodo_mixup/fold_test_RFMiD_v1/\n================================================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}