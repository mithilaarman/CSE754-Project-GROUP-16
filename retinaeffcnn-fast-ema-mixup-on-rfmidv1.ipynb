{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2530487,"sourceType":"datasetVersion","datasetId":1533360},{"sourceId":13811294,"sourceType":"datasetVersion","datasetId":8794300},{"sourceId":13894314,"sourceType":"datasetVersion","datasetId":8852034}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================\n# FULL MODIFIED CODE: Parameter-Efficient Custom CNN + Mixup DG\n# (Train: ODIR + RFMiD_v2, Test: RFMiD_v1)\n# ============================================================\n\nimport os\nimport random\nfrom typing import Dict\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\n\nimport torchvision.transforms as transforms\n\nfrom sklearn.metrics import roc_auc_score, f1_score, roc_curve, average_precision_score\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n\n# =============================================================================\n# (A) HARMONIZATION UTILITIES\n# =============================================================================\n\ndef harmonize_odir(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/odir-clr/ODIR_CLR\"\n\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_ Set/train_images\"\n        label_file = f\"{base_path}/Training_ Set/train_annotation.xlsx\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Validation_set/val_images\"\n        label_file = f\"{base_path}/Validation_set/val_annotation.xlsx\"\n    else:\n        img_dir = f\"{base_path}/Test_Set/test_images\"\n        label_file = f\"{base_path}/Test_Set/test_annotation.xlsx\"\n\n    df = pd.read_excel(label_file)\n    label_cols = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n    harmonized_rows = []\n\n    for _, row in df.iterrows():\n        patient_id = row['ID']\n        labels = {col: int(row[col]) for col in label_cols}\n\n        if pd.notna(row.get('Left-Fundus')) and str(row['Left-Fundus']).strip():\n            left_path = os.path.join(img_dir, f\"{patient_id}_left.jpg\")\n            harmonized_rows.append({\n                'image_path': left_path,\n                'dataset': 'ODIR',\n                'split': split,\n                'ID': patient_id,\n                **labels\n            })\n\n        if pd.notna(row.get('Right-Fundus')) and str(row['Right-Fundus']).strip():\n            right_path = os.path.join(img_dir, f\"{patient_id}_right.jpg\")\n            harmonized_rows.append({\n                'image_path': right_path,\n                'dataset': 'ODIR',\n                'split': split,\n                'ID': patient_id,\n                **labels\n            })\n\n    return pd.DataFrame(harmonized_rows)\n\n\ndef harmonize_rfmid_v1(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/retinal-disease-classification\"\n\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_Set/Training_Set/Training\"\n        label_file = f\"{base_path}/Training_Set/Training_Set/RFMiD_Training_Labels.csv\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Evaluation_Set/Evaluation_Set/Validation\"\n        label_file = f\"{base_path}/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv\"\n    else:\n        img_dir = f\"{base_path}/Test_Set/Test_Set/Test\"\n        label_file = f\"{base_path}/Test_Set/Test_Set/RFMiD_Testing_Labels.csv\"\n\n    df = pd.read_csv(label_file)\n\n    all_disease_cols = ['DR', 'ARMD', 'MH', 'DN', 'MYA', 'BRVO', 'TSLN',\n                        'ERM', 'LS', 'MS', 'CSR', 'ODC', 'CRVO', 'TV', 'AH',\n                        'ODP', 'ODE', 'ST', 'AION', 'PT', 'RT', 'RS', 'CRS',\n                        'EDN', 'RPEC', 'MHL', 'RP', 'CWS', 'CB', 'ODPM',\n                        'PRH', 'MNF', 'HR', 'CRAO', 'TD', 'CME', 'PTCR', 'CF',\n                        'VH', 'MCA', 'VS', 'BRAO', 'PLQ', 'HPED', 'CL']\n\n    harmonized_rows = []\n\n    for _, row in df.iterrows():\n        image_id = row['ID']\n\n        image_path = None\n        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n            candidate = os.path.join(img_dir, f\"{image_id}{ext}\")\n            if os.path.exists(candidate):\n                image_path = candidate\n                break\n        if image_path is None:\n            image_path = os.path.join(img_dir, str(image_id))\n\n        # Direct single-column mapping\n        N = 1 if row['Disease_Risk'] == 0 else 0\n        D = 1 if row.get('DR', 0) == 1 else 0\n        G = 1 if row.get('ODC', 0) == 1 else 0\n        C = 1 if row.get('MH', 0) == 1 else 0\n        A = 1 if row.get('ARMD', 0) == 1 else 0\n        H = 1 if row.get('HR', 0) == 1 else 0\n        M = 1 if row.get('MYA', 0) == 1 else 0\n\n        used_for_mapping = ['DR', 'ODC', 'MH', 'ARMD', 'HR', 'MYA']\n        other_cols = [col for col in all_disease_cols if col not in used_for_mapping]\n        O = 1 if any(row.get(col, 0) == 1 for col in other_cols) else 0\n\n        harmonized_rows.append({\n            'image_path': image_path,\n            'dataset': 'RFMiD_v1',\n            'split': split,\n            'ID': image_id,\n            'N': N, 'D': D, 'G': G, 'C': C, 'A': A, 'H': H, 'M': M, 'O': O\n        })\n\n    return pd.DataFrame(harmonized_rows)\n\n\ndef harmonize_rfmid_v2(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/rdc-version-2/RFDiM2_0\"\n\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_set_2/Train_2\"\n        label_file = f\"{base_path}/Training_set_2/RFMiD_2_Training_labels.csv\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Validation_set_2/Validation_2\"\n        label_file = f\"{base_path}/Validation_set_2/RFMiD_2_Validation_labels.csv\"\n    else:\n        img_dir = f\"{base_path}/Test_set_2/Test_2\"\n        label_file = f\"{base_path}/Test_set_2/RFMiD_2_Testing_labels.csv\"\n\n    try:\n        df = pd.read_csv(label_file, encoding='utf-8')\n    except UnicodeDecodeError:\n        df = pd.read_csv(label_file, encoding='latin1')\n\n    df.columns = df.columns.str.strip()\n\n    potential_disease_cols = ['AH', 'AION', 'ARMD', 'BRVO', 'CB', 'CF', 'CL', 'CME',\n                              'CNV', 'CRAO', 'CRS', 'CRVO', 'CSR', 'CWS', 'CSC', 'DN',\n                              'DR', 'EDN', 'ERM', 'GRT', 'HPED', 'HR', 'LS', 'MCA',\n                              'ME', 'MH', 'MHL', 'MS', 'MYA', 'ODC', 'ODE', 'ODP',\n                              'ON', 'OPDM', 'PRH', 'RD', 'RHL', 'RTR', 'RP', 'RPEC',\n                              'RS', 'RT', 'SOFE', 'ST', 'TD', 'TSLN', 'TV', 'VS',\n                              'HTN', 'IIH']\n\n    all_disease_cols = [col for col in potential_disease_cols if col in df.columns]\n    harmonized_rows = []\n\n    skipped_count = 0\n    found_count = 0\n\n    for _, row in df.iterrows():\n        image_id = int(row['ID'])\n\n        image_path = None\n        for ext in ['.jpg', '.JPG', '.png', '.PNG', '.jpeg', '.JPEG']:\n            candidate = os.path.join(img_dir, f\"{image_id}{ext}\")\n            if os.path.exists(candidate):\n                image_path = candidate\n                found_count += 1\n                break\n\n        if image_path is None:\n            skipped_count += 1\n            continue\n\n        # Map labels (v2 uses WNL for Normal)\n        wnl = row.get('WNL', 0)\n        N = 1 if wnl == 1 else 0\n        D = 1 if row.get('DR', 0) == 1 else 0\n        G = 1 if row.get('ODC', 0) == 1 else 0\n        C = 1 if row.get('MH', 0) == 1 else 0\n        A = 1 if row.get('ARMD', 0) == 1 else 0\n\n        # H: prefer HTN if present else HR fallback\n        H = 1 if row.get('HTN', 0) == 1 else 0\n        if H == 0 and 'HR' in df.columns:\n            H = 1 if row.get('HR', 0) == 1 else 0\n\n        M = 1 if row.get('MYA', 0) == 1 else 0\n\n        used_for_mapping = ['DR', 'ODC', 'MH', 'ARMD', 'HTN', 'HR', 'MYA', 'WNL']\n        other_cols = [col for col in all_disease_cols if col not in used_for_mapping]\n        O = 1 if any(row.get(col, 0) == 1 for col in other_cols) else 0\n\n        harmonized_rows.append({\n            'image_path': image_path,\n            'dataset': 'RFMiD_v2',\n            'split': split,\n            'ID': image_id,\n            'N': N, 'D': D, 'G': G, 'C': C, 'A': A, 'H': H, 'M': M, 'O': O\n        })\n\n    if skipped_count > 0:\n        print(f\"RFMiD_v2 {split}: Found {found_count}, Skipped {skipped_count}\")\n\n    return pd.DataFrame(harmonized_rows)\n\n\ndef harmonize_all_datasets() -> Dict[str, pd.DataFrame]:\n    results = {}\n\n    print(\"\\n\" + \"=\" * 60)\n    print(\"HARMONIZING DATASETS\")\n    print(\"=\" * 60)\n\n    for split in ['train', 'val', 'test']:\n        print(f\"\\nProcessing {split} split...\")\n        results[f'ODIR_{split}'] = harmonize_odir(split)\n        results[f'RFMiD_v1_{split}'] = harmonize_rfmid_v1(split)\n        results[f'RFMiD_v2_{split}'] = harmonize_rfmid_v2(split)\n\n    return results\n\n\ndef print_statistics(harmonized_data: Dict[str, pd.DataFrame]):\n    label_cols = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n\n    print(\"\\n\" + \"=\" * 60)\n    print(\"DATASET STATISTICS\")\n    print(\"=\" * 60)\n\n    print(\"\\nðŸ“Š Sample Counts:\")\n    print(\"-\" * 40)\n    for key, df in sorted(harmonized_data.items()):\n        print(f\"{key:20s}: {len(df):5d} images\")\n\n    total_train = sum(len(df) for k, df in harmonized_data.items() if 'train' in k)\n    total_val = sum(len(df) for k, df in harmonized_data.items() if 'val' in k)\n    total_test = sum(len(df) for k, df in harmonized_data.items() if 'test' in k)\n\n    print(\"-\" * 40)\n    print(f\"{'Total Train':20s}: {total_train:5d} images\")\n    print(f\"{'Total Val':20s}: {total_val:5d} images\")\n    print(f\"{'Total Test':20s}: {total_test:5d} images\")\n    print(f\"{'Grand Total':20s}: {total_train + total_val + total_test:5d} images\")\n\n    for dataset_name in ['ODIR', 'RFMiD_v1', 'RFMiD_v2']:\n        dataset_dfs = {k: v for k, v in harmonized_data.items() if k.startswith(dataset_name)}\n        if not dataset_dfs:\n            continue\n\n        print(f\"\\n{'=' * 60}\")\n        print(f\"{dataset_name} Label Distribution\")\n        print(f\"{'=' * 60}\")\n\n        for split in ['train', 'val', 'test']:\n            key = f\"{dataset_name}_{split}\"\n            if key not in dataset_dfs:\n                continue\n\n            df = dataset_dfs[key]\n            print(f\"\\n{split.upper()} ({len(df)} images):\")\n            print(\"-\" * 40)\n            for col in label_cols:\n                count = df[col].sum()\n                pct = (count / len(df)) * 100 if len(df) > 0 else 0\n                print(f\"  {col}: {count:5d} ({pct:5.1f}%)\")\n\n\ndef save_harmonized_data(harmonized_data: Dict[str, pd.DataFrame], output_dir: str = './harmonized_labels'):\n    os.makedirs(output_dir, exist_ok=True)\n\n    print(\"\\n\" + \"=\" * 60)\n    print(\"SAVING HARMONIZED DATA\")\n    print(\"=\" * 60)\n\n    for key, df in harmonized_data.items():\n        output_path = os.path.join(output_dir, f\"{key}.csv\")\n        df.to_csv(output_path, index=False)\n        print(f\"âœ… Saved {key:20s}: {len(df):5d} rows â†’ {output_path}\")\n\n    print(\"\\nðŸ“¦ Creating combined files...\")\n    for split in ['train', 'val', 'test']:\n        split_dfs = [v for k, v in harmonized_data.items() if k.endswith(f'_{split}')]\n        if split_dfs:\n            combined = pd.concat(split_dfs, ignore_index=True)\n            output_path = os.path.join(output_dir, f\"combined_{split}.csv\")\n            combined.to_csv(output_path, index=False)\n            print(f\"âœ… Saved combined_{split:5s}: {len(combined):5d} rows â†’ {output_path}\")\n\n    print(f\"\\nâœ¨ All files saved to: {output_dir}\")\n\n\ndef verify_images(harmonized_data: Dict[str, pd.DataFrame]):\n    \"\"\"Verify that all image paths in the harmonized data actually exist\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"VERIFYING IMAGE PATHS\")\n    print(\"=\" * 60)\n\n    all_good = True\n    for key, df in sorted(harmonized_data.items()):\n        missing = df[~df['image_path'].apply(os.path.exists)]\n        if len(missing) > 0:\n            print(f\"âŒ {key:20s}: {len(missing)} missing images\")\n            all_good = False\n        else:\n            print(f\"âœ… {key:20s}: All {len(df)} images found\")\n\n    if all_good:\n        print(\"\\nðŸŽ‰ All image paths verified successfully!\")\n    else:\n        print(\"\\nâš ï¸  Some images are missing - check the paths above\")\n\n\n# =============================================================================\n# (B) CONFIG for FOLD (Swapped: Train=ODIR+RFMiD_v2, Test=RFMiD_v1)\n# =============================================================================\n\nSEED = 42\nSAVE_DIR = './results_lodo_mixup/custom_cnn_fold_test_RFMiD_v1'\nTEST_DOMAIN = \"RFMiD_v1\"\nTRAIN_DOMAINS = \"ODIR + RFMiD_v2\"\n\nMIXUP_ALPHA = 0.2  # Controls mixing strength\n\n# Paths (SWAPPED ROLES)\nTEST_CSV = '/kaggle/working/harmonized_labels/RFMiD_v1_test.csv'\nTRAIN_CSVS = [\n    '/kaggle/working/harmonized_labels/ODIR_train.csv',\n    '/kaggle/working/harmonized_labels/RFMiD_v2_train.csv'\n]\nVAL_CSVS = [\n    '/kaggle/working/harmonized_labels/ODIR_val.csv',\n    '/kaggle/working/harmonized_labels/RFMiD_v2_val.csv'\n]\n\n\n# =============================================================================\n# Reproducibility\n# =============================================================================\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n\n# =============================================================================\n# Dataset (with domain tracking for Mixup!)\n# =============================================================================\n\nclass RetinalDataset(Dataset):\n    def __init__(self, csv_path, domain_id, transform=None):\n        self.data = pd.read_csv(csv_path)\n        self.domain_id = domain_id\n        self.transform = transform\n        self.label_cols = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n\n        dup = self.data.duplicated(subset=[\"image_path\"], keep=\"first\").sum()\n        if dup > 0:\n            print(f\"[WARN] {dup} duplicates found in {csv_path}, keeping first\")\n        self.data = self.data.drop_duplicates(subset=[\"image_path\"]).reset_index(drop=True)\n\n        valid_mask = self.data[\"image_path\"].apply(os.path.exists)\n        missing = (~valid_mask).sum()\n        if missing > 0:\n            print(f\"[WARN] Dropping {missing} missing images from {csv_path}\")\n        self.data = self.data.loc[valid_mask].reset_index(drop=True)\n        print(f\"[INFO] Domain {domain_id}: Loaded {len(self.data)} valid images from {os.path.basename(csv_path)}\")\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        try:\n            image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n        except Exception:\n            image = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n\n        labels = torch.tensor(row[self.label_cols].values.astype(\"float32\"))\n        if self.transform:\n            image = self.transform(image)\n        return image, labels, self.domain_id\n\n\n# =============================================================================\n# Pos weight\n# =============================================================================\n\ndef calculate_pos_weights(datasets, clip_min=0.5, clip_max=50.0):\n    all_labels = []\n    for ds in datasets:\n        all_labels.append(ds.data[[\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]].values)\n    combined = np.vstack(all_labels)\n\n    pos = combined.sum(axis=0)\n    neg = len(combined) - pos\n    raw = neg / (pos + 1e-5)\n    clipped = np.clip(raw, clip_min, clip_max)\n\n    print(\"\\n[INFO] Positive class weights (from training domains):\")\n    for i, col in enumerate([\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]):\n        print(f\"  {col}: {clipped[i]:.2f}\")\n\n    return torch.tensor(clipped, dtype=torch.float32)\n\n\n# =============================================================================\n# (C) PARAMETER-EFFICIENT CUSTOM CNN (Depthwise-Separable)\n# =============================================================================\n\nclass SEBlock(nn.Module):\n    \"\"\"Squeeze-and-Excitation block (very small overhead, often helps).\"\"\"\n    def __init__(self, channels: int, reduction: int = 8):\n        super().__init__()\n        hidden = max(4, channels // reduction)\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n            nn.Linear(channels, hidden),\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden, channels),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.shape\n        y = self.pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\n\n\nclass DepthwiseSeparableConv(nn.Module):\n    \"\"\"\n    Depthwise Separable Conv:\n      - depthwise: groups=in_ch\n      - pointwise: 1x1\n    Much fewer params than standard conv.\n    \"\"\"\n    def __init__(self, in_ch: int, out_ch: int, stride: int = 1, use_se: bool = True):\n        super().__init__()\n        self.dw = nn.Conv2d(in_ch, in_ch, kernel_size=3, stride=stride, padding=1,\n                            groups=in_ch, bias=False)\n        self.dw_bn = nn.BatchNorm2d(in_ch)\n        self.pw = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False)\n        self.pw_bn = nn.BatchNorm2d(out_ch)\n        self.act = nn.SiLU(inplace=True)  # efficient + strong\n        self.se = SEBlock(out_ch) if use_se else nn.Identity()\n\n    def forward(self, x):\n        x = self.act(self.dw_bn(self.dw(x)))\n        x = self.act(self.pw_bn(self.pw(x)))\n        x = self.se(x)\n        return x\n\n\nclass TinyRetinaCNN(nn.Module):\n    \"\"\"\n    Parameter-efficient CNN backbone + classifier head.\n    Designed to be much smaller than ResNet50 but still strong.\n    \"\"\"\n    def __init__(self, num_classes: int = 8, width_mult: float = 1.0, dropout: float = 0.3):\n        super().__init__()\n\n        def c(ch):  # channel scaling\n            return max(8, int(ch * width_mult))\n\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, c(32), kernel_size=3, stride=2, padding=1, bias=False),  # 224->112\n            nn.BatchNorm2d(c(32)),\n            nn.SiLU(inplace=True),\n        )\n\n        # Stages: progressively downsample to get global semantics\n        self.stage1 = nn.Sequential(\n            DepthwiseSeparableConv(c(32), c(48), stride=1, use_se=True),\n            DepthwiseSeparableConv(c(48), c(64), stride=2, use_se=True),   # 112->56\n        )\n        self.stage2 = nn.Sequential(\n            DepthwiseSeparableConv(c(64), c(96), stride=1, use_se=True),\n            DepthwiseSeparableConv(c(96), c(128), stride=2, use_se=True),  # 56->28\n        )\n        self.stage3 = nn.Sequential(\n            DepthwiseSeparableConv(c(128), c(160), stride=1, use_se=True),\n            DepthwiseSeparableConv(c(160), c(192), stride=2, use_se=True), # 28->14\n        )\n        self.stage4 = nn.Sequential(\n            DepthwiseSeparableConv(c(192), c(256), stride=2, use_se=True), # 14->7\n            DepthwiseSeparableConv(c(256), c(256), stride=1, use_se=True),\n        )\n\n        self.pool = nn.AdaptiveAvgPool2d(1)\n\n        self.classifier = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(c(256), c(256)),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(c(256)),\n            nn.Dropout(dropout),\n            nn.Linear(c(256), num_classes)\n        )\n\n        self._init_weights()\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.stage1(x)\n        x = self.stage2(x)\n        x = self.stage3(x)\n        x = self.stage4(x)\n        x = self.pool(x).flatten(1)\n        return self.classifier(x)\n\n\n# =============================================================================\n# Transforms\n# =============================================================================\n\ndef get_transforms(is_train=False):\n    if is_train:\n        return transforms.Compose([\n            transforms.Resize((256, 256)),\n            transforms.RandomCrop(224),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n\n\n# =============================================================================\n# Metrics\n# =============================================================================\n\ndef compute_metrics(labels, probs, thresholds=None):\n    n_classes = labels.shape[1]\n\n    aucs = []\n    for i in range(n_classes):\n        if len(np.unique(labels[:, i])) > 1:\n            aucs.append(roc_auc_score(labels[:, i], probs[:, i]))\n        else:\n            aucs.append(np.nan)\n\n    aps = []\n    for i in range(n_classes):\n        if len(np.unique(labels[:, i])) > 1:\n            aps.append(average_precision_score(labels[:, i], probs[:, i]))\n        else:\n            aps.append(np.nan)\n\n    if thresholds is None:\n        thresholds = np.full(n_classes, 0.5)\n\n    preds = (probs >= thresholds).astype(int)\n    f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n\n    return {\n        \"mAUC\": float(np.nanmean(aucs)),\n        \"mAP\": float(np.nanmean(aps)),\n        \"per_class_auc\": aucs,\n        \"per_class_ap\": aps,\n        \"macro_f1\": float(f1),\n    }\n\n\ndef find_optimal_thresholds(labels, probs):\n    n_classes = labels.shape[1]\n    thresholds = []\n    search_range = np.linspace(0.05, 0.95, 91)\n\n    for i in range(n_classes):\n        best_f1, best_t = 0.0, 0.5\n        if len(np.unique(labels[:, i])) > 1:\n            for t in search_range:\n                preds = (probs[:, i] >= t).astype(int)\n                f1 = f1_score(labels[:, i], preds, zero_division=0)\n                if f1 > best_f1:\n                    best_f1, best_t = f1, t\n        thresholds.append(best_t)\n\n    return np.array(thresholds)\n\n\n# =============================================================================\n# MIXUP TRAINING (inter-domain)\n# =============================================================================\n\ndef train_epoch_mixup(model, loaders_dict, criterion, optimizer, device, mixup_alpha=0.2):\n    model.train()\n    losses = []\n    mixup_stats = {'total_batches': 0, 'mixup_batches': 0}\n\n    domain_iters = {k: iter(v) for k, v in loaders_dict.items()}\n    domain_ids = list(loaders_dict.keys())\n\n    max_batches = max(len(loader) for loader in loaders_dict.values())\n    pbar = tqdm(range(max_batches), desc=\"Train (Mixup)\", leave=False)\n\n    for _ in pbar:\n        if len(domain_ids) >= 2 and np.random.rand() > 0.5:\n            d1, d2 = np.random.choice(domain_ids, size=2, replace=False)\n\n            try:\n                imgs1, labels1, _ = next(domain_iters[d1])\n            except StopIteration:\n                domain_iters[d1] = iter(loaders_dict[d1])\n                imgs1, labels1, _ = next(domain_iters[d1])\n\n            try:\n                imgs2, labels2, _ = next(domain_iters[d2])\n            except StopIteration:\n                domain_iters[d2] = iter(loaders_dict[d2])\n                imgs2, labels2, _ = next(domain_iters[d2])\n\n            min_size = min(imgs1.size(0), imgs2.size(0))\n            imgs1, labels1 = imgs1[:min_size], labels1[:min_size]\n            imgs2, labels2 = imgs2[:min_size], labels2[:min_size]\n\n            lam = np.random.beta(mixup_alpha, mixup_alpha)\n\n            mixed_imgs = lam * imgs1 + (1 - lam) * imgs2\n            mixed_labels = lam * labels1 + (1 - lam) * labels2\n\n            mixed_imgs = mixed_imgs.to(device)\n            mixed_labels = mixed_labels.to(device)\n\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(mixed_imgs)\n            loss = criterion(logits, mixed_labels)\n\n            mixup_stats['mixup_batches'] += 1\n\n        else:\n            d = np.random.choice(domain_ids)\n            try:\n                imgs, labels, _ = next(domain_iters[d])\n            except StopIteration:\n                domain_iters[d] = iter(loaders_dict[d])\n                imgs, labels, _ = next(domain_iters[d])\n\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            optimizer.zero_grad(set_to_none=True)\n            logits = model(imgs)\n            loss = criterion(logits, labels)\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        losses.append(loss.item())\n        mixup_stats['total_batches'] += 1\n        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n\n    return {\n        \"loss\": float(np.mean(losses)),\n        \"mixup_ratio\": mixup_stats['mixup_batches'] / max(1, mixup_stats['total_batches'])\n    }\n\n\n@torch.no_grad()\ndef validate(model, loader, criterion, device, thresholds=None):\n    model.eval()\n    losses, all_probs, all_labels = [], [], []\n\n    for batch in tqdm(loader, desc=\"Val\", leave=False):\n        if len(batch) == 3:\n            images, labels, _ = batch\n        else:\n            images, labels = batch\n\n        images, labels = images.to(device), labels.to(device)\n        logits = model(images)\n        loss = criterion(logits, labels)\n\n        losses.append(loss.item())\n        all_probs.append(torch.sigmoid(logits).cpu().numpy())\n        all_labels.append(labels.cpu().numpy())\n\n    probs = np.vstack(all_probs)\n    labels = np.vstack(all_labels)\n    metrics = compute_metrics(labels, probs, thresholds)\n    metrics[\"loss\"] = float(np.mean(losses))\n    return metrics, probs, labels\n\n\n# =============================================================================\n# Visualizations\n# =============================================================================\n\ndef plot_training_curves(history, save_dir):\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    epochs = range(1, len(history['train_loss']) + 1)\n\n    axes[0].plot(epochs, history['train_loss'], linewidth=2, label='Train Loss', marker='o')\n    axes[0].plot(epochs, history['val_loss'], linewidth=2, label='Val Loss', marker='s')\n    axes[0].set_xlabel('Epoch')\n    axes[0].set_ylabel('Loss')\n    axes[0].set_title('Training and Validation Loss (Mixup)')\n    axes[0].legend()\n    axes[0].grid(True, alpha=0.3)\n\n    axes[1].plot(epochs, history['val_auc'], linewidth=2, label='Val mAUC', marker='s')\n    axes[1].set_xlabel('Epoch')\n    axes[1].set_ylabel('mAUC')\n    axes[1].set_title('Validation mAUC (Mixup)')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n    axes[1].set_ylim([0, 1.0])\n\n    plt.tight_layout()\n    plt.savefig(f'{save_dir}/training_curves.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"[INFO] âœ“ Saved training curves\")\n\n\ndef plot_per_class_roc(labels, probs, test_domain, save_dir):\n    class_names = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n    n_classes = 8\n\n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n    axes = axes.flatten()\n\n    for i in range(n_classes):\n        if len(np.unique(labels[:, i])) > 1:\n            fpr, tpr, _ = roc_curve(labels[:, i], probs[:, i])\n            auc = roc_auc_score(labels[:, i], probs[:, i])\n\n            axes[i].plot(fpr, tpr, linewidth=2, label=f'AUC = {auc:.3f}')\n            axes[i].plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5)\n            axes[i].set_xlabel('False Positive Rate')\n            axes[i].set_ylabel('True Positive Rate')\n            axes[i].set_title(f'Class {class_names[i]}')\n            axes[i].legend(loc='lower right')\n            axes[i].grid(True, alpha=0.3)\n        else:\n            axes[i].text(0.5, 0.5, 'Single class\\n(No ROC)', ha='center', va='center', fontsize=12)\n            axes[i].set_title(f'Class {class_names[i]}')\n\n    plt.suptitle(f'Per-Class ROC Curves - Test on {test_domain} (Mixup)', y=0.995)\n    plt.tight_layout()\n    plt.savefig(f'{save_dir}/per_class_roc_curves.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"[INFO] âœ“ Saved per-class ROC curves\")\n\n\ndef plot_macro_roc(labels, probs, test_domain, save_dir):\n    n_classes = 8\n    fig, ax = plt.subplots(figsize=(8, 6))\n\n    all_fpr, all_tpr = [], []\n    for i in range(n_classes):\n        if len(np.unique(labels[:, i])) > 1:\n            fpr, tpr, _ = roc_curve(labels[:, i], probs[:, i])\n            all_fpr.append(fpr)\n            all_tpr.append(tpr)\n\n    mean_fpr = np.linspace(0, 1, 100)\n    tprs = [np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(all_fpr, all_tpr)]\n    mean_tpr = np.mean(tprs, axis=0)\n    macro_auc = np.trapz(mean_tpr, mean_fpr)\n\n    ax.plot(mean_fpr, mean_tpr, linewidth=3, label=f'Macro-avg ROC (AUC = {macro_auc:.3f})')\n    ax.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.5, label='Random')\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    ax.set_title(f'Macro-Average ROC Curve - Test on {test_domain} (Mixup)')\n    ax.legend(loc='lower right')\n    ax.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig(f'{save_dir}/macro_roc_curve.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"[INFO] âœ“ Saved macro-average ROC curve\")\n\n\ndef plot_per_class_metrics(test_metrics, save_dir):\n    class_names = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n    aucs = test_metrics['per_class_auc']\n    aps = test_metrics['per_class_ap']\n\n    aucs = [auc if not np.isnan(auc) else 0 for auc in aucs]\n    aps = [ap if not np.isnan(ap) else 0 for ap in aps]\n\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    x = np.arange(len(class_names))\n\n    axes[0].bar(x, aucs, alpha=0.8, edgecolor='black', linewidth=1.5)\n    axes[0].set_xlabel('Disease Class')\n    axes[0].set_ylabel('AUC')\n    axes[0].set_title('Per-Class AUC (Mixup)')\n    axes[0].set_xticks(x)\n    axes[0].set_xticklabels(class_names)\n    axes[0].set_ylim([0, 1.0])\n    axes[0].grid(True, alpha=0.3, axis='y')\n    for i, auc in enumerate(aucs):\n        axes[0].text(i, auc + 0.02, f'{auc:.2f}', ha='center', fontsize=9)\n\n    axes[1].bar(x, aps, alpha=0.8, edgecolor='black', linewidth=1.5)\n    axes[1].set_xlabel('Disease Class')\n    axes[1].set_ylabel('Average Precision')\n    axes[1].set_title('Per-Class Average Precision (Mixup)')\n    axes[1].set_xticks(x)\n    axes[1].set_xticklabels(class_names)\n    axes[1].set_ylim([0, 1.0])\n    axes[1].grid(True, alpha=0.3, axis='y')\n    for i, ap in enumerate(aps):\n        axes[1].text(i, ap + 0.02, f'{ap:.2f}', ha='center', fontsize=9)\n\n    plt.tight_layout()\n    plt.savefig(f'{save_dir}/per_class_metrics.png', dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"[INFO] âœ“ Saved per-class metrics chart\")\n\n\n# =============================================================================\n# (D) MAIN TRAINING SCRIPT\n# =============================================================================\n\ndef count_parameters(model: nn.Module) -> int:\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\nif __name__ == \"__main__\":\n    # ---- (1) Harmonize + Save (optional: comment out if already done)\n    harmonized_data = harmonize_all_datasets()\n    print_statistics(harmonized_data)\n    verify_images(harmonized_data)\n    save_harmonized_data(harmonized_data, output_dir='./harmonized_labels')\n\n    # ---- (2) Train / Val / Test\n    set_seed(SEED)\n    os.makedirs(SAVE_DIR, exist_ok=True)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    print(\"=\" * 80)\n    print(f\"LODO FOLD (SWAPPED) with MIXUP DG: Test on {TEST_DOMAIN}\")\n    print(f\"Training on: {TRAIN_DOMAINS}\")\n    print(\"=\" * 80)\n    print(f\"Device: {device}\")\n    print(f\"Seed: {SEED}\")\n    print(f\"Mixup Alpha: {MIXUP_ALPHA}\")\n    print(\"=\" * 80)\n\n    print(\"\\n[INFO] Loading datasets...\")\n    train_datasets = [RetinalDataset(csv, domain_id=i, transform=get_transforms(True))\n                      for i, csv in enumerate(TRAIN_CSVS)]\n    val_datasets = [RetinalDataset(csv, domain_id=i, transform=get_transforms(False))\n                    for i, csv in enumerate(VAL_CSVS)]\n    test_dataset = RetinalDataset(TEST_CSV, domain_id=999, transform=get_transforms(False))\n\n    print(f\"\\n[INFO] Total train: {sum(len(ds) for ds in train_datasets)} images\")\n    print(f\"[INFO] Total val:   {sum(len(ds) for ds in val_datasets)} images\")\n    print(f\"[INFO] Test:        {len(test_dataset)} images\")\n\n    pos_weights = calculate_pos_weights(train_datasets).to(device)\n\n    g = torch.Generator().manual_seed(SEED)\n    train_loaders = {\n        i: DataLoader(ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, generator=g)\n        for i, ds in enumerate(train_datasets)\n    }\n\n    combined_val = ConcatDataset(val_datasets)\n    val_loader = DataLoader(combined_val, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n\n    # ---- Custom CNN model (parameter-efficient)\n    print(\"\\n[INFO] Initializing Parameter-Efficient Custom CNN...\")\n    model = TinyRetinaCNN(num_classes=8, width_mult=1.0, dropout=0.3).to(device)\n    print(f\"[INFO] Trainable params: {count_parameters(model):,}\")\n\n    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n\n    # Single LR optimizer (no backbone/head split needed now)\n    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=3\n    )\n\n    history = {\n        'train_loss': [],\n        'val_loss': [],\n        'val_auc': []\n    }\n\n    best_val_auc, patience_counter = 0.0, 0\n    print(\"\\n[INFO] Training started with Mixup DG...\")\n    print(\"-\" * 80)\n\n    for epoch in range(50):\n        train_metrics = train_epoch_mixup(\n            model, train_loaders, criterion, optimizer, device, mixup_alpha=MIXUP_ALPHA\n        )\n        val_metrics, _, _ = validate(model, val_loader, criterion, device)\n        scheduler.step(val_metrics['mAUC'])\n\n        history['train_loss'].append(train_metrics['loss'])\n        history['val_loss'].append(val_metrics['loss'])\n        history['val_auc'].append(val_metrics['mAUC'])\n\n        print(f\"Epoch {epoch + 1:02d} | Train Loss: {train_metrics['loss']:.4f} \"\n              f\"| Val mAUC: {val_metrics['mAUC']:.4f} | Mixup: {train_metrics['mixup_ratio']:.1%}\")\n\n        if val_metrics['mAUC'] > best_val_auc:\n            best_val_auc = val_metrics['mAUC']\n            torch.save(model.state_dict(), f'{SAVE_DIR}/best_model.pth')\n            print(f\"  âœ“ Saved best model (val mAUC: {best_val_auc:.4f})\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n\n        if patience_counter >= 10:\n            print(f\"\\n[INFO] Early stopping at epoch {epoch + 1}\")\n            break\n\n    print(f\"\\n[INFO] Loading best model...\")\n    model.load_state_dict(torch.load(f'{SAVE_DIR}/best_model.pth', map_location=device))\n    print(f\"[INFO] Best validation mAUC: {best_val_auc:.4f}\")\n\n    print(f\"\\n[INFO] Finding optimal thresholds on validation...\")\n    _, val_probs, val_labels = validate(model, val_loader, criterion, device)\n    thresholds = find_optimal_thresholds(val_labels, val_probs)\n\n    class_names = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n    print(\"[INFO] Optimal thresholds:\")\n    for c, t in zip(class_names, thresholds):\n        print(f\"  {c}: {t:.3f}\")\n\n    print(f\"\\n[INFO] Testing on {TEST_DOMAIN}...\")\n    print(\"-\" * 80)\n    test_metrics, test_probs, test_labels = validate(model, test_loader, criterion, device, thresholds)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"TEST RESULTS - {TEST_DOMAIN} (Mixup DG) - Custom CNN\")\n    print(\"=\" * 80)\n    print(f\"mAUC:      {test_metrics['mAUC']:.4f}\")\n    print(f\"mAP:       {test_metrics['mAP']:.4f}\")\n    print(f\"Macro F1:  {test_metrics['macro_f1']:.4f}\")\n    print(\"=\" * 80)\n\n    print(f\"\\n{'Class':<8} {'AUC':<10} {'AP':<10}\")\n    print(\"-\" * 30)\n    for i, cls in enumerate(class_names):\n        auc = test_metrics['per_class_auc'][i]\n        ap = test_metrics['per_class_ap'][i]\n        auc_str = f\"{auc:.4f}\" if not np.isnan(auc) else \"N/A\"\n        ap_str = f\"{ap:.4f}\" if not np.isnan(ap) else \"N/A\"\n        print(f\"{cls:<8} {auc_str:<10} {ap_str:<10}\")\n    print(\"-\" * 30)\n\n    print(\"\\n[INFO] Saving results...\")\n    results_df = pd.DataFrame([{\n        'method': 'Mixup + CustomCNN',\n        'test_domain': TEST_DOMAIN,\n        'train_domains': TRAIN_DOMAINS,\n        'mAUC': test_metrics['mAUC'],\n        'mAP': test_metrics['mAP'],\n        'macro_f1': test_metrics['macro_f1'],\n        'best_val_auc': best_val_auc,\n        'mixup_alpha': MIXUP_ALPHA,\n        'trainable_params': count_parameters(model)\n    }])\n    results_df.to_csv(f'{SAVE_DIR}/test_results.csv', index=False)\n    print(f\"[INFO] âœ“ Saved test_results.csv\")\n\n    print(\"\\n[INFO] Generating visualizations...\")\n    plot_training_curves(history, SAVE_DIR)\n    plot_per_class_roc(test_labels, test_probs, TEST_DOMAIN, SAVE_DIR)\n    plot_macro_roc(test_labels, test_probs, TEST_DOMAIN, SAVE_DIR)\n    plot_per_class_metrics(test_metrics, SAVE_DIR)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"âœ“ MIXUP LODO FOLD (SWAPPED) COMPLETE!\")\n    print(f\"âœ“ Results saved to: {SAVE_DIR}/\")\n    print(\"=\" * 80)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-18T05:07:35.678872Z","iopub.execute_input":"2026-01-18T05:07:35.679200Z","iopub.status.idle":"2026-01-18T07:32:36.076977Z","shell.execute_reply.started":"2026-01-18T05:07:35.679168Z","shell.execute_reply":"2026-01-18T07:32:36.076206Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nHARMONIZING DATASETS\n============================================================\n\nProcessing train split...\nRFMiD_v2 train: Found 507, Skipped 2\n\nProcessing val split...\n\nProcessing test split...\nRFMiD_v2 test: Found 170, Skipped 4\n\n============================================================\nDATASET STATISTICS\n============================================================\n\nðŸ“Š Sample Counts:\n----------------------------------------\nODIR_test           :  2000 images\nODIR_train          :  7000 images\nODIR_val            :  1000 images\nRFMiD_v1_test       :   640 images\nRFMiD_v1_train      :  1920 images\nRFMiD_v1_val        :   640 images\nRFMiD_v2_test       :   170 images\nRFMiD_v2_train      :   507 images\nRFMiD_v2_val        :   177 images\n----------------------------------------\nTotal Train         :  9427 images\nTotal Val           :  1817 images\nTotal Test          :  2810 images\nGrand Total         : 14054 images\n\n============================================================\nODIR Label Distribution\n============================================================\n\nTRAIN (7000 images):\n----------------------------------------\n  N:  2280 ( 32.6%)\n  D:  2256 ( 32.2%)\n  G:   430 (  6.1%)\n  C:   424 (  6.1%)\n  A:   328 (  4.7%)\n  H:   206 (  2.9%)\n  M:   348 (  5.0%)\n  O:  1958 ( 28.0%)\n\nVAL (1000 images):\n----------------------------------------\n  N:   324 ( 32.4%)\n  D:   326 ( 32.6%)\n  G:    64 (  6.4%)\n  C:    62 (  6.2%)\n  A:    50 (  5.0%)\n  H:    32 (  3.2%)\n  M:    46 (  4.6%)\n  O:   272 ( 27.2%)\n\nTEST (2000 images):\n----------------------------------------\n  N:   648 ( 32.4%)\n  D:   654 ( 32.7%)\n  G:   116 (  5.8%)\n  C:   130 (  6.5%)\n  A:    98 (  4.9%)\n  H:    60 (  3.0%)\n  M:    92 (  4.6%)\n  O:   550 ( 27.5%)\n\n============================================================\nRFMiD_v1 Label Distribution\n============================================================\n\nTRAIN (1920 images):\n----------------------------------------\n  N:   401 ( 20.9%)\n  D:   376 ( 19.6%)\n  G:   282 ( 14.7%)\n  C:   317 ( 16.5%)\n  A:   100 (  5.2%)\n  H:     0 (  0.0%)\n  M:   101 (  5.3%)\n  O:   785 ( 40.9%)\n\nVAL (640 images):\n----------------------------------------\n  N:   134 ( 20.9%)\n  D:   132 ( 20.6%)\n  G:    72 ( 11.2%)\n  C:   102 ( 15.9%)\n  A:    38 (  5.9%)\n  H:     0 (  0.0%)\n  M:    34 (  5.3%)\n  O:   271 ( 42.3%)\n\nTEST (640 images):\n----------------------------------------\n  N:   134 ( 20.9%)\n  D:   124 ( 19.4%)\n  G:    91 ( 14.2%)\n  C:   104 ( 16.2%)\n  A:    31 (  4.8%)\n  H:     1 (  0.2%)\n  M:    32 (  5.0%)\n  O:   257 ( 40.2%)\n\n============================================================\nRFMiD_v2 Label Distribution\n============================================================\n\nTRAIN (507 images):\n----------------------------------------\n  N:   156 ( 30.8%)\n  D:    42 (  8.3%)\n  G:    21 (  4.1%)\n  C:    26 (  5.1%)\n  A:     5 (  1.0%)\n  H:    64 ( 12.6%)\n  M:    27 (  5.3%)\n  O:   256 ( 50.5%)\n\nVAL (177 images):\n----------------------------------------\n  N:    53 ( 29.9%)\n  D:    14 (  7.9%)\n  G:     9 (  5.1%)\n  C:     8 (  4.5%)\n  A:     3 (  1.7%)\n  H:    13 (  7.3%)\n  M:    11 (  6.2%)\n  O:    89 ( 50.3%)\n\nTEST (170 images):\n----------------------------------------\n  N:    52 ( 30.6%)\n  D:    14 (  8.2%)\n  G:     7 (  4.1%)\n  C:     7 (  4.1%)\n  A:     2 (  1.2%)\n  H:    18 ( 10.6%)\n  M:     5 (  2.9%)\n  O:    89 ( 52.4%)\n\n============================================================\nVERIFYING IMAGE PATHS\n============================================================\nâœ… ODIR_test           : All 2000 images found\nâœ… ODIR_train          : All 7000 images found\nâœ… ODIR_val            : All 1000 images found\nâœ… RFMiD_v1_test       : All 640 images found\nâœ… RFMiD_v1_train      : All 1920 images found\nâœ… RFMiD_v1_val        : All 640 images found\nâœ… RFMiD_v2_test       : All 170 images found\nâœ… RFMiD_v2_train      : All 507 images found\nâœ… RFMiD_v2_val        : All 177 images found\n\nðŸŽ‰ All image paths verified successfully!\n\n============================================================\nSAVING HARMONIZED DATA\n============================================================\nâœ… Saved ODIR_train          :  7000 rows â†’ ./harmonized_labels/ODIR_train.csv\nâœ… Saved RFMiD_v1_train      :  1920 rows â†’ ./harmonized_labels/RFMiD_v1_train.csv\nâœ… Saved RFMiD_v2_train      :   507 rows â†’ ./harmonized_labels/RFMiD_v2_train.csv\nâœ… Saved ODIR_val            :  1000 rows â†’ ./harmonized_labels/ODIR_val.csv\nâœ… Saved RFMiD_v1_val        :   640 rows â†’ ./harmonized_labels/RFMiD_v1_val.csv\nâœ… Saved RFMiD_v2_val        :   177 rows â†’ ./harmonized_labels/RFMiD_v2_val.csv\nâœ… Saved ODIR_test           :  2000 rows â†’ ./harmonized_labels/ODIR_test.csv\nâœ… Saved RFMiD_v1_test       :   640 rows â†’ ./harmonized_labels/RFMiD_v1_test.csv\nâœ… Saved RFMiD_v2_test       :   170 rows â†’ ./harmonized_labels/RFMiD_v2_test.csv\n\nðŸ“¦ Creating combined files...\nâœ… Saved combined_train:  9427 rows â†’ ./harmonized_labels/combined_train.csv\nâœ… Saved combined_val  :  1817 rows â†’ ./harmonized_labels/combined_val.csv\nâœ… Saved combined_test :  2810 rows â†’ ./harmonized_labels/combined_test.csv\n\nâœ¨ All files saved to: ./harmonized_labels\n================================================================================\nLODO FOLD (SWAPPED) with MIXUP DG: Test on RFMiD_v1\nTraining on: ODIR + RFMiD_v2\n================================================================================\nDevice: cuda\nSeed: 42\nMixup Alpha: 0.2\n================================================================================\n\n[INFO] Loading datasets...\n[INFO] Domain 0: Loaded 7000 valid images from ODIR_train.csv\n[INFO] Domain 1: Loaded 507 valid images from RFMiD_v2_train.csv\n[INFO] Domain 0: Loaded 1000 valid images from ODIR_val.csv\n[INFO] Domain 1: Loaded 177 valid images from RFMiD_v2_val.csv\n[INFO] Domain 999: Loaded 640 valid images from RFMiD_v1_test.csv\n\n[INFO] Total train: 7507 images\n[INFO] Total val:   1177 images\n[INFO] Test:        640 images\n\n[INFO] Positive class weights (from training domains):\n  N: 2.08\n  D: 2.27\n  G: 15.65\n  C: 15.68\n  A: 21.54\n  H: 26.80\n  M: 19.02\n  O: 2.39\n\n[INFO] Initializing Parameter-Efficient Custom CNN...\n[INFO] Trainable params: 329,086\n\n[INFO] Training started with Mixup DG...\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | Train Loss: 1.3703 | Val mAUC: 0.6103 | Mixup: 53.9%\n  âœ“ Saved best model (val mAUC: 0.6103)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | Train Loss: 1.1782 | Val mAUC: 0.5911 | Mixup: 44.3%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | Train Loss: 1.0945 | Val mAUC: 0.6272 | Mixup: 51.6%\n  âœ“ Saved best model (val mAUC: 0.6272)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | Train Loss: 1.0789 | Val mAUC: 0.6524 | Mixup: 48.4%\n  âœ“ Saved best model (val mAUC: 0.6524)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | Train Loss: 1.0532 | Val mAUC: 0.6697 | Mixup: 50.2%\n  âœ“ Saved best model (val mAUC: 0.6697)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 06 | Train Loss: 1.0193 | Val mAUC: 0.6624 | Mixup: 46.6%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 07 | Train Loss: 1.0010 | Val mAUC: 0.6589 | Mixup: 53.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 08 | Train Loss: 0.9383 | Val mAUC: 0.6871 | Mixup: 46.6%\n  âœ“ Saved best model (val mAUC: 0.6871)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 09 | Train Loss: 0.9612 | Val mAUC: 0.6867 | Mixup: 52.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.8934 | Val mAUC: 0.6939 | Mixup: 52.5%\n  âœ“ Saved best model (val mAUC: 0.6939)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | Train Loss: 0.9330 | Val mAUC: 0.7020 | Mixup: 48.4%\n  âœ“ Saved best model (val mAUC: 0.7020)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | Train Loss: 0.9143 | Val mAUC: 0.6856 | Mixup: 51.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | Train Loss: 0.8486 | Val mAUC: 0.6978 | Mixup: 47.5%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | Train Loss: 0.8605 | Val mAUC: 0.7091 | Mixup: 52.1%\n  âœ“ Saved best model (val mAUC: 0.7091)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | Train Loss: 0.8451 | Val mAUC: 0.7118 | Mixup: 42.5%\n  âœ“ Saved best model (val mAUC: 0.7118)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 16 | Train Loss: 0.8422 | Val mAUC: 0.7033 | Mixup: 46.6%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 17 | Train Loss: 0.8445 | Val mAUC: 0.7012 | Mixup: 50.7%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 18 | Train Loss: 0.8134 | Val mAUC: 0.6826 | Mixup: 46.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 19 | Train Loss: 0.8396 | Val mAUC: 0.7011 | Mixup: 53.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 20 | Train Loss: 0.7460 | Val mAUC: 0.7012 | Mixup: 48.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 21 | Train Loss: 0.7668 | Val mAUC: 0.7121 | Mixup: 50.2%\n  âœ“ Saved best model (val mAUC: 0.7121)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 22 | Train Loss: 0.7764 | Val mAUC: 0.7132 | Mixup: 54.3%\n  âœ“ Saved best model (val mAUC: 0.7132)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 23 | Train Loss: 0.7714 | Val mAUC: 0.7144 | Mixup: 54.3%\n  âœ“ Saved best model (val mAUC: 0.7144)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 24 | Train Loss: 0.7801 | Val mAUC: 0.7137 | Mixup: 50.2%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 25 | Train Loss: 0.7808 | Val mAUC: 0.7173 | Mixup: 53.0%\n  âœ“ Saved best model (val mAUC: 0.7173)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 26 | Train Loss: 0.7699 | Val mAUC: 0.7169 | Mixup: 51.6%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 27 | Train Loss: 0.7212 | Val mAUC: 0.7203 | Mixup: 51.1%\n  âœ“ Saved best model (val mAUC: 0.7203)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 28 | Train Loss: 0.7488 | Val mAUC: 0.7254 | Mixup: 46.6%\n  âœ“ Saved best model (val mAUC: 0.7254)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 29 | Train Loss: 0.7524 | Val mAUC: 0.7209 | Mixup: 52.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 30 | Train Loss: 0.7573 | Val mAUC: 0.7222 | Mixup: 56.2%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 31 | Train Loss: 0.6818 | Val mAUC: 0.7242 | Mixup: 49.3%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 32 | Train Loss: 0.7260 | Val mAUC: 0.7149 | Mixup: 45.7%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 33 | Train Loss: 0.7243 | Val mAUC: 0.7174 | Mixup: 45.7%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 34 | Train Loss: 0.7131 | Val mAUC: 0.7266 | Mixup: 53.0%\n  âœ“ Saved best model (val mAUC: 0.7266)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 35 | Train Loss: 0.7258 | Val mAUC: 0.7244 | Mixup: 57.5%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 36 | Train Loss: 0.7117 | Val mAUC: 0.7205 | Mixup: 52.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 37 | Train Loss: 0.6696 | Val mAUC: 0.7245 | Mixup: 48.9%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 38 | Train Loss: 0.7226 | Val mAUC: 0.7171 | Mixup: 51.1%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 39 | Train Loss: 0.7277 | Val mAUC: 0.7210 | Mixup: 56.6%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 40 | Train Loss: 0.7719 | Val mAUC: 0.7232 | Mixup: 48.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 41 | Train Loss: 0.6887 | Val mAUC: 0.7242 | Mixup: 47.5%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 42 | Train Loss: 0.7562 | Val mAUC: 0.7279 | Mixup: 50.7%\n  âœ“ Saved best model (val mAUC: 0.7279)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 43 | Train Loss: 0.7323 | Val mAUC: 0.7293 | Mixup: 51.1%\n  âœ“ Saved best model (val mAUC: 0.7293)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 44 | Train Loss: 0.6776 | Val mAUC: 0.7312 | Mixup: 48.4%\n  âœ“ Saved best model (val mAUC: 0.7312)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 45 | Train Loss: 0.6721 | Val mAUC: 0.7222 | Mixup: 48.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 46 | Train Loss: 0.7061 | Val mAUC: 0.7248 | Mixup: 46.6%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 47 | Train Loss: 0.6461 | Val mAUC: 0.7242 | Mixup: 47.5%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 48 | Train Loss: 0.7072 | Val mAUC: 0.7269 | Mixup: 49.3%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             ","output_type":"stream"},{"name":"stdout","text":"Epoch 49 | Train Loss: 0.7187 | Val mAUC: 0.7066 | Mixup: 59.4%\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 50 | Train Loss: 0.6857 | Val mAUC: 0.7253 | Mixup: 49.8%\n\n[INFO] Loading best model...\n[INFO] Best validation mAUC: 0.7312\n\n[INFO] Finding optimal thresholds on validation...\n","output_type":"stream"},{"name":"stderr","text":"                                                    \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Optimal thresholds:\n  N: 0.260\n  D: 0.290\n  G: 0.370\n  C: 0.840\n  A: 0.440\n  H: 0.480\n  M: 0.600\n  O: 0.480\n\n[INFO] Testing on RFMiD_v1...\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nTEST RESULTS - RFMiD_v1 (Mixup DG) - Custom CNN\n================================================================================\nmAUC:      0.7778\nmAP:       0.4223\nMacro F1:  0.3709\n================================================================================\n\nClass    AUC        AP        \n------------------------------\nN        0.8740     0.7033    \nD        0.7304     0.4344    \nG        0.6281     0.2272    \nC        0.8890     0.7086    \nA        0.7655     0.2036    \nH        0.7449     0.0061    \nM        0.9421     0.5878    \nO        0.6479     0.5077    \n------------------------------\n\n[INFO] Saving results...\n[INFO] âœ“ Saved test_results.csv\n\n[INFO] Generating visualizations...\n[INFO] âœ“ Saved training curves\n[INFO] âœ“ Saved per-class ROC curves\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/395585924.py:791: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n  macro_auc = np.trapz(mean_tpr, mean_fpr)\n","output_type":"stream"},{"name":"stdout","text":"[INFO] âœ“ Saved macro-average ROC curve\n[INFO] âœ“ Saved per-class metrics chart\n\n================================================================================\nâœ“ MIXUP LODO FOLD (SWAPPED) COMPLETE!\nâœ“ Results saved to: ./results_lodo_mixup/custom_cnn_fold_test_RFMiD_v1/\n================================================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================\n# FAST + STRONG RetinaEffCNN (same architecture) + Mixup/CutMix + EMA + ASL\n# Train: ODIR + RFMiD_v2 | Test: RFMiD_v1\n# ============================================================\n\nimport os\nimport random\nfrom typing import Dict, Optional, Tuple\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\n\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import roc_auc_score, f1_score, average_precision_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# PIL safety (helps avoid rare crashes)\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n# =============================================================================\n# (A) HARMONIZATION UTILITIES (same logic as your working version)\n# =============================================================================\n\ndef harmonize_odir(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/odir-clr/ODIR_CLR\"\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_ Set/train_images\"\n        label_file = f\"{base_path}/Training_ Set/train_annotation.xlsx\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Validation_set/val_images\"\n        label_file = f\"{base_path}/Validation_set/val_annotation.xlsx\"\n    else:\n        img_dir = f\"{base_path}/Test_Set/test_images\"\n        label_file = f\"{base_path}/Test_Set/test_annotation.xlsx\"\n\n    df = pd.read_excel(label_file)\n    label_cols = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n    rows = []\n\n    for _, row in df.iterrows():\n        pid = row['ID']\n        labels = {c: int(row[c]) for c in label_cols}\n\n        if pd.notna(row.get('Left-Fundus')) and str(row['Left-Fundus']).strip():\n            rows.append({\n                \"image_path\": os.path.join(img_dir, f\"{pid}_left.jpg\"),\n                \"dataset\": \"ODIR\", \"split\": split, \"ID\": pid, **labels\n            })\n\n        if pd.notna(row.get('Right-Fundus')) and str(row['Right-Fundus']).strip():\n            rows.append({\n                \"image_path\": os.path.join(img_dir, f\"{pid}_right.jpg\"),\n                \"dataset\": \"ODIR\", \"split\": split, \"ID\": pid, **labels\n            })\n\n    return pd.DataFrame(rows)\n\n\ndef harmonize_rfmid_v1(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/retinal-disease-classification\"\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_Set/Training_Set/Training\"\n        label_file = f\"{base_path}/Training_Set/Training_Set/RFMiD_Training_Labels.csv\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Evaluation_Set/Evaluation_Set/Validation\"\n        label_file = f\"{base_path}/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv\"\n    else:\n        img_dir = f\"{base_path}/Test_Set/Test_Set/Test\"\n        label_file = f\"{base_path}/Test_Set/Test_Set/RFMiD_Testing_Labels.csv\"\n\n    df = pd.read_csv(label_file)\n\n    all_disease_cols = ['DR', 'ARMD', 'MH', 'DN', 'MYA', 'BRVO', 'TSLN',\n                        'ERM', 'LS', 'MS', 'CSR', 'ODC', 'CRVO', 'TV', 'AH',\n                        'ODP', 'ODE', 'ST', 'AION', 'PT', 'RT', 'RS', 'CRS',\n                        'EDN', 'RPEC', 'MHL', 'RP', 'CWS', 'CB', 'ODPM',\n                        'PRH', 'MNF', 'HR', 'CRAO', 'TD', 'CME', 'PTCR', 'CF',\n                        'VH', 'MCA', 'VS', 'BRAO', 'PLQ', 'HPED', 'CL']\n\n    rows = []\n    for _, row in df.iterrows():\n        image_id = row['ID']\n        image_path = None\n        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n            cand = os.path.join(img_dir, f\"{image_id}{ext}\")\n            if os.path.exists(cand):\n                image_path = cand\n                break\n        if image_path is None:\n            image_path = os.path.join(img_dir, str(image_id))\n\n        N = 1 if row['Disease_Risk'] == 0 else 0\n        D = 1 if row.get('DR', 0) == 1 else 0\n        G = 1 if row.get('ODC', 0) == 1 else 0\n        C = 1 if row.get('MH', 0) == 1 else 0\n        A = 1 if row.get('ARMD', 0) == 1 else 0\n        H = 1 if row.get('HR', 0) == 1 else 0\n        M = 1 if row.get('MYA', 0) == 1 else 0\n\n        used = ['DR', 'ODC', 'MH', 'ARMD', 'HR', 'MYA']\n        other_cols = [c for c in all_disease_cols if c not in used]\n        O = 1 if any(row.get(c, 0) == 1 for c in other_cols) else 0\n\n        rows.append({\n            \"image_path\": image_path, \"dataset\": \"RFMiD_v1\", \"split\": split, \"ID\": image_id,\n            \"N\": N, \"D\": D, \"G\": G, \"C\": C, \"A\": A, \"H\": H, \"M\": M, \"O\": O\n        })\n\n    return pd.DataFrame(rows)\n\n\ndef harmonize_rfmid_v2(split: str) -> pd.DataFrame:\n    base_path = \"/kaggle/input/rdc-version-2/RFDiM2_0\"\n    if split == \"train\":\n        img_dir = f\"{base_path}/Training_set_2/Train_2\"\n        label_file = f\"{base_path}/Training_set_2/RFMiD_2_Training_labels.csv\"\n    elif split == \"val\":\n        img_dir = f\"{base_path}/Validation_set_2/Validation_2\"\n        label_file = f\"{base_path}/Validation_set_2/RFMiD_2_Validation_labels.csv\"\n    else:\n        img_dir = f\"{base_path}/Test_set_2/Test_2\"\n        label_file = f\"{base_path}/Test_set_2/RFMiD_2_Testing_labels.csv\"\n\n    try:\n        df = pd.read_csv(label_file, encoding=\"utf-8\")\n    except UnicodeDecodeError:\n        df = pd.read_csv(label_file, encoding=\"latin1\")\n\n    df.columns = df.columns.str.strip()\n\n    potential = ['AH', 'AION', 'ARMD', 'BRVO', 'CB', 'CF', 'CL', 'CME',\n                 'CNV', 'CRAO', 'CRS', 'CRVO', 'CSR', 'CWS', 'CSC', 'DN',\n                 'DR', 'EDN', 'ERM', 'GRT', 'HPED', 'HR', 'LS', 'MCA',\n                 'ME', 'MH', 'MHL', 'MS', 'MYA', 'ODC', 'ODE', 'ODP',\n                 'ON', 'OPDM', 'PRH', 'RD', 'RHL', 'RTR', 'RP', 'RPEC',\n                 'RS', 'RT', 'SOFE', 'ST', 'TD', 'TSLN', 'TV', 'VS',\n                 'HTN', 'IIH']\n\n    all_disease_cols = [c for c in potential if c in df.columns]\n    rows = []\n    found, skipped = 0, 0\n\n    for _, row in df.iterrows():\n        image_id = int(row[\"ID\"])\n        image_path = None\n        for ext in ['.jpg', '.JPG', '.png', '.PNG', '.jpeg', '.JPEG']:\n            cand = os.path.join(img_dir, f\"{image_id}{ext}\")\n            if os.path.exists(cand):\n                image_path = cand\n                found += 1\n                break\n        if image_path is None:\n            skipped += 1\n            continue\n\n        N = 1 if row.get(\"WNL\", 0) == 1 else 0\n        D = 1 if row.get(\"DR\", 0) == 1 else 0\n        G = 1 if row.get(\"ODC\", 0) == 1 else 0\n        C = 1 if row.get(\"MH\", 0) == 1 else 0\n        A = 1 if row.get(\"ARMD\", 0) == 1 else 0\n\n        H = 1 if row.get(\"HTN\", 0) == 1 else 0\n        if H == 0 and \"HR\" in df.columns:\n            H = 1 if row.get(\"HR\", 0) == 1 else 0\n\n        M = 1 if row.get(\"MYA\", 0) == 1 else 0\n\n        used = ['DR', 'ODC', 'MH', 'ARMD', 'HTN', 'HR', 'MYA', 'WNL']\n        other_cols = [c for c in all_disease_cols if c not in used]\n        O = 1 if any(row.get(c, 0) == 1 for c in other_cols) else 0\n\n        rows.append({\n            \"image_path\": image_path, \"dataset\": \"RFMiD_v2\", \"split\": split, \"ID\": image_id,\n            \"N\": N, \"D\": D, \"G\": G, \"C\": C, \"A\": A, \"H\": H, \"M\": M, \"O\": O\n        })\n\n    if skipped > 0:\n        print(f\"RFMiD_v2 {split}: Found {found}, Skipped {skipped}\")\n\n    return pd.DataFrame(rows)\n\n\ndef harmonize_all_datasets() -> Dict[str, pd.DataFrame]:\n    out = {}\n    print(\"\\n\" + \"=\" * 60)\n    print(\"HARMONIZING DATASETS\")\n    print(\"=\" * 60)\n    for split in [\"train\", \"val\", \"test\"]:\n        print(f\"\\nProcessing {split} split...\")\n        out[f\"ODIR_{split}\"] = harmonize_odir(split)\n        out[f\"RFMiD_v1_{split}\"] = harmonize_rfmid_v1(split)\n        out[f\"RFMiD_v2_{split}\"] = harmonize_rfmid_v2(split)\n    return out\n\n\ndef save_harmonized_data(harmonized_data: Dict[str, pd.DataFrame], output_dir: str = \"./harmonized_labels\"):\n    os.makedirs(output_dir, exist_ok=True)\n    for k, df in harmonized_data.items():\n        df.to_csv(os.path.join(output_dir, f\"{k}.csv\"), index=False)\n\n\n# =============================================================================\n# (B) CONFIG (FAST_MODE defaults ON)\n# =============================================================================\n\nFAST_MODE = True  # <- keep True for speed; set False for heavier training.\n\nSEED = 42\nSAVE_DIR = \"./results_lodo_mixup/retinaeffcnn_fast\"\nTEST_DOMAIN = \"RFMiD_v1\"\nTRAIN_DOMAINS = \"ODIR + RFMiD_v2\"\n\nif FAST_MODE:\n    IMG_SIZE = 288\n    BATCH_SIZE = 32\n    ACCUM_STEPS = 1\n    EPOCHS = 35\n    EARLY_STOP_PATIENCE = 8\n    MIXUP_ALPHA = 0.20\n    P_MIX = 0.55\n    P_CUTMIX_IN_MIX = 0.45\n    LABEL_SMOOTH = 0.01\n    USE_TTA_ON_TEST = False\n    WIDTH_MULT = 1.20\nelse:\n    IMG_SIZE = 320\n    BATCH_SIZE = 24\n    ACCUM_STEPS = 2\n    EPOCHS = 60\n    EARLY_STOP_PATIENCE = 12\n    MIXUP_ALPHA = 0.25\n    P_MIX = 0.60\n    P_CUTMIX_IN_MIX = 0.55\n    LABEL_SMOOTH = 0.02\n    USE_TTA_ON_TEST = True\n    WIDTH_MULT = 1.35  # bigger but slower\n\nEMA_DECAY = 0.999\nUSE_AMP = True\n\nASL_GAMMA_POS = 0.0\nASL_GAMMA_NEG = 2.0\nASL_CLIP = 0.05\n\nTEST_CSV = \"/kaggle/working/harmonized_labels/RFMiD_v1_test.csv\"\nTRAIN_CSVS = [\n    \"/kaggle/working/harmonized_labels/ODIR_train.csv\",\n    \"/kaggle/working/harmonized_labels/RFMiD_v2_train.csv\",\n]\nVAL_CSVS = [\n    \"/kaggle/working/harmonized_labels/ODIR_val.csv\",\n    \"/kaggle/working/harmonized_labels/RFMiD_v2_val.csv\",\n]\n\n\n# =============================================================================\n# Reproducibility + speed knobs\n# =============================================================================\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = True\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    try:\n        torch.set_float32_matmul_precision(\"high\")\n    except Exception:\n        pass\n\n\n# =============================================================================\n# Dataset\n# =============================================================================\n\nclass RetinalDataset(Dataset):\n    def __init__(self, csv_path, domain_id, transform=None):\n        self.data = pd.read_csv(csv_path)\n        self.domain_id = domain_id\n        self.transform = transform\n        self.label_cols = [\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]\n\n        self.data = self.data.drop_duplicates(subset=[\"image_path\"]).reset_index(drop=True)\n        valid = self.data[\"image_path\"].apply(os.path.exists)\n        self.data = self.data.loc[valid].reset_index(drop=True)\n\n        print(f\"[INFO] Domain {domain_id}: Loaded {len(self.data)} images from {os.path.basename(csv_path)}\")\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        try:\n            img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n        except Exception:\n            img = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), color=(128, 128, 128))\n\n        y = torch.tensor(row[self.label_cols].values.astype(\"float32\"))\n\n        if self.transform:\n            img = self.transform(img)\n        return img, y, self.domain_id\n\n\ndef calculate_pos_weights(datasets, clip_min=0.5, clip_max=50.0):\n    arr = []\n    for ds in datasets:\n        arr.append(ds.data[[\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]].values)\n    combined = np.vstack(arr)\n    pos = combined.sum(axis=0)\n    neg = len(combined) - pos\n    w = neg / (pos + 1e-5)\n    w = np.clip(w, clip_min, clip_max)\n\n    print(\"\\n[INFO] Positive class weights:\")\n    for i, c in enumerate([\"N\", \"D\", \"G\", \"C\", \"A\", \"H\", \"M\", \"O\"]):\n        print(f\"  {c}: {w[i]:.2f}\")\n    return torch.tensor(w, dtype=torch.float32)\n\n\n# =============================================================================\n# (C) SAME CNN ARCHITECTURE (RetinaEffCNN) - only width_mult configurable\n# =============================================================================\n\nclass DropPath(nn.Module):\n    def __init__(self, drop_prob: float = 0.0):\n        super().__init__()\n        self.drop_prob = drop_prob\n\n    def forward(self, x):\n        if self.drop_prob == 0.0 or (not self.training):\n            return x\n        keep_prob = 1 - self.drop_prob\n        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n        rnd = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n        rnd.floor_()\n        return x.div(keep_prob) * rnd\n\n\nclass SEBlock(nn.Module):\n    def __init__(self, channels: int, reduction: int = 4):\n        super().__init__()\n        hidden = max(8, channels // reduction)\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Linear(channels, hidden)\n        self.fc2 = nn.Linear(hidden, channels)\n\n    def forward(self, x):\n        b, c, _, _ = x.shape\n        y = self.pool(x).view(b, c)\n        y = torch.relu(self.fc1(y))\n        y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1)\n        return x * y\n\n\nclass InvertedResidual(nn.Module):\n    def __init__(self, in_ch, out_ch, stride, expand_ratio, use_se=True, drop_path=0.0):\n        super().__init__()\n        assert stride in [1, 2]\n        self.use_res = (stride == 1 and in_ch == out_ch)\n        hidden = int(round(in_ch * expand_ratio))\n\n        if expand_ratio != 1:\n            self.expand = nn.Sequential(\n                nn.Conv2d(in_ch, hidden, 1, bias=False),\n                nn.BatchNorm2d(hidden),\n                nn.SiLU(inplace=True),\n            )\n        else:\n            self.expand = nn.Identity()\n\n        self.dw = nn.Sequential(\n            nn.Conv2d(hidden, hidden, 3, stride=stride, padding=1, groups=hidden, bias=False),\n            nn.BatchNorm2d(hidden),\n            nn.SiLU(inplace=True),\n        )\n\n        self.se = SEBlock(hidden) if use_se else nn.Identity()\n\n        self.project = nn.Sequential(\n            nn.Conv2d(hidden, out_ch, 1, bias=False),\n            nn.BatchNorm2d(out_ch),\n        )\n\n        self.drop_path = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n\n    def forward(self, x):\n        out = self.expand(x)\n        out = self.dw(out)\n        out = self.se(out)\n        out = self.project(out)\n        if self.use_res:\n            out = x + self.drop_path(out)\n        return out\n\n\nclass RetinaEffCNN(nn.Module):\n    def __init__(self, num_classes=8, width_mult=1.20, dropout=0.35, drop_path_rate=0.10):\n        super().__init__()\n\n        def c(ch):\n            return max(8, int(ch * width_mult))\n\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, c(24), 3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(c(24)),\n            nn.SiLU(inplace=True),\n        )\n\n        cfg = [\n            (c(24),  c(24),  1, 1.0, True),\n            (c(24),  c(32),  2, 4.0, True),\n            (c(32),  c(32),  1, 3.0, True),\n\n            (c(32),  c(48),  2, 4.0, True),\n            (c(48),  c(48),  1, 3.0, True),\n\n            (c(48),  c(80),  2, 4.0, True),\n            (c(80),  c(80),  1, 3.0, True),\n            (c(80),  c(96),  1, 3.0, True),\n\n            (c(96),  c(160), 2, 6.0, True),\n            (c(160), c(160), 1, 6.0, True),\n        ]\n\n        blocks = []\n        n = len(cfg)\n        for i, (inch, outch, s, exp, se) in enumerate(cfg):\n            dp = drop_path_rate * i / max(1, n - 1)\n            blocks.append(InvertedResidual(inch, outch, s, exp, use_se=se, drop_path=dp))\n        self.blocks = nn.Sequential(*blocks)\n\n        self.head = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(1),\n            nn.Dropout(dropout),\n            nn.Linear(c(160), c(256)),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(c(256)),\n            nn.Dropout(dropout),\n            nn.Linear(c(256), num_classes),\n        )\n\n        self._init()\n\n    def _init(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n                nn.init.ones_(m.weight); nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.stem(x)\n        x = self.blocks(x)\n        x = self.head(x)\n        return x\n\n\ndef count_parameters(model: nn.Module) -> int:\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\n# =============================================================================\n# (D) Asymmetric Loss\n# =============================================================================\n\nclass AsymmetricLoss(nn.Module):\n    def __init__(self, gamma_pos=0.0, gamma_neg=2.0, clip=0.05, eps=1e-8, pos_weight=None):\n        super().__init__()\n        self.gp = gamma_pos\n        self.gn = gamma_neg\n        self.clip = clip\n        self.eps = eps\n        self.register_buffer(\"pos_weight\", pos_weight if pos_weight is not None else None)\n\n    def forward(self, logits, targets):\n        targets = targets.clamp(0, 1)\n        x = torch.sigmoid(logits)\n\n        xs_pos = x\n        xs_neg = 1.0 - x\n        if self.clip and self.clip > 0:\n            xs_neg = (xs_neg + self.clip).clamp(max=1.0)\n\n        loss_pos = targets * torch.log(xs_pos.clamp(min=self.eps))\n        loss_neg = (1 - targets) * torch.log(xs_neg.clamp(min=self.eps))\n        loss = loss_pos + loss_neg\n\n        if self.gp > 0 or self.gn > 0:\n            pt = xs_pos * targets + xs_neg * (1 - targets)\n            gamma = self.gp * targets + self.gn * (1 - targets)\n            loss *= torch.pow(1 - pt, gamma)\n\n        if self.pos_weight is not None:\n            loss *= (targets * self.pos_weight + (1 - targets))\n\n        return -loss.mean()\n\n\n# =============================================================================\n# Transforms (FASTER than your previous heavy pipeline)\n# =============================================================================\n\ndef get_transforms(is_train=False):\n    if is_train:\n        # fast but still good\n        return transforms.Compose([\n            transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n            transforms.RandomCrop(IMG_SIZE),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomRotation(8),\n            transforms.ColorJitter(brightness=0.18, contrast=0.18, saturation=0.08, hue=0.02),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n            transforms.RandomErasing(p=0.12, scale=(0.02, 0.10), ratio=(0.3, 3.3), value='random')\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize((IMG_SIZE + 32, IMG_SIZE + 32)),\n            transforms.CenterCrop(IMG_SIZE),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n\n\n# =============================================================================\n# Metrics\n# =============================================================================\n\ndef compute_metrics(labels, probs, thresholds=None):\n    n = labels.shape[1]\n    aucs, aps = [], []\n\n    for i in range(n):\n        if len(np.unique(labels[:, i])) > 1:\n            aucs.append(roc_auc_score(labels[:, i], probs[:, i]))\n            aps.append(average_precision_score(labels[:, i], probs[:, i]))\n        else:\n            aucs.append(np.nan)\n            aps.append(np.nan)\n\n    if thresholds is None:\n        thresholds = np.full(n, 0.5)\n\n    preds = (probs >= thresholds).astype(int)\n    f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n\n    return {\n        \"mAUC\": float(np.nanmean(aucs)),\n        \"mAP\": float(np.nanmean(aps)),\n        \"per_class_auc\": aucs,\n        \"per_class_ap\": aps,\n        \"macro_f1\": float(f1),\n    }\n\n\ndef find_optimal_thresholds(labels, probs):\n    n = labels.shape[1]\n    thresholds = []\n    grid = np.linspace(0.05, 0.95, 91)\n    for i in range(n):\n        best_f1, best_t = 0.0, 0.5\n        if len(np.unique(labels[:, i])) > 1:\n            for t in grid:\n                pred = (probs[:, i] >= t).astype(int)\n                f1 = f1_score(labels[:, i], pred, zero_division=0)\n                if f1 > best_f1:\n                    best_f1, best_t = f1, t\n        thresholds.append(best_t)\n    return np.array(thresholds)\n\n\n# =============================================================================\n# Mixup/CutMix (inter-domain)\n# =============================================================================\n\ndef smooth_labels(y: torch.Tensor, eps: float) -> torch.Tensor:\n    if eps <= 0:\n        return y\n    return y * (1 - eps) + 0.5 * eps\n\n\ndef rand_bbox(W: int, H: int, lam: float) -> Tuple[int, int, int, int]:\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n    x1 = np.clip(cx - cut_w // 2, 0, W)\n    y1 = np.clip(cy - cut_h // 2, 0, H)\n    x2 = np.clip(cx + cut_w // 2, 0, W)\n    y2 = np.clip(cy + cut_h // 2, 0, H)\n    return x1, y1, x2, y2\n\n\ndef interdomain_mix(imgs1, labels1, imgs2, labels2, alpha, p_cutmix=0.5):\n    lam = np.random.beta(alpha, alpha)\n    if np.random.rand() < p_cutmix:\n        B, C, H, W = imgs1.shape\n        x1, y1, x2, y2 = rand_bbox(W, H, lam)\n        imgs = imgs1.clone()\n        imgs[:, :, y1:y2, x1:x2] = imgs2[:, :, y1:y2, x1:x2]\n        area = (x2 - x1) * (y2 - y1)\n        lam_adj = 1.0 - area / float(W * H)\n        labels = lam_adj * labels1 + (1 - lam_adj) * labels2\n        return imgs, labels\n    else:\n        imgs = lam * imgs1 + (1 - lam) * imgs2\n        labels = lam * labels1 + (1 - lam) * labels2\n        return imgs, labels\n\n\n# =============================================================================\n# EMA\n# =============================================================================\n\nclass ModelEMA:\n    def __init__(self, model: nn.Module, decay: float = 0.999):\n        self.decay = decay\n        self.shadow = {n: p.detach().clone() for n, p in model.named_parameters() if p.requires_grad}\n\n    @torch.no_grad()\n    def update(self, model: nn.Module):\n        for n, p in model.named_parameters():\n            if n in self.shadow:\n                self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1 - self.decay)\n\n    def apply_to(self, model: nn.Module):\n        self._backup = {}\n        for n, p in model.named_parameters():\n            if n in self.shadow:\n                self._backup[n] = p.detach().clone()\n                p.data.copy_(self.shadow[n].data)\n\n    def restore(self, model: nn.Module):\n        for n, p in model.named_parameters():\n            if n in getattr(self, \"_backup\", {}):\n                p.data.copy_(self._backup[n].data)\n        self._backup = {}\n\n\n# =============================================================================\n# Train/Val (scheduler steps ONLY on optimizer update)\n# =============================================================================\n\ndef train_epoch_mixup(\n    model, loaders_dict, criterion, optimizer, device,\n    scaler: Optional[torch.amp.GradScaler],\n    ema: Optional[ModelEMA],\n    scheduler: Optional[optim.lr_scheduler._LRScheduler],\n    epoch_steps: int\n):\n    model.train()\n    losses = []\n    mix_ratio = 0\n\n    iters = {k: iter(v) for k, v in loaders_dict.items()}\n    domain_ids = list(loaders_dict.keys())\n\n    optimizer.zero_grad(set_to_none=True)\n\n    pbar = tqdm(range(epoch_steps), desc=\"Train\", leave=False)\n    for step in pbar:\n        do_mix = (len(domain_ids) >= 2) and (np.random.rand() < P_MIX)\n\n        if do_mix:\n            d1, d2 = np.random.choice(domain_ids, size=2, replace=False)\n            try:\n                imgs1, labels1, _ = next(iters[d1])\n            except StopIteration:\n                iters[d1] = iter(loaders_dict[d1])\n                imgs1, labels1, _ = next(iters[d1])\n\n            try:\n                imgs2, labels2, _ = next(iters[d2])\n            except StopIteration:\n                iters[d2] = iter(loaders_dict[d2])\n                imgs2, labels2, _ = next(iters[d2])\n\n            m = min(imgs1.size(0), imgs2.size(0))\n            imgs1, labels1 = imgs1[:m], labels1[:m]\n            imgs2, labels2 = imgs2[:m], labels2[:m]\n\n            imgs, labels = interdomain_mix(imgs1, labels1, imgs2, labels2, MIXUP_ALPHA, P_CUTMIX_IN_MIX)\n            mix_ratio += 1\n        else:\n            d = np.random.choice(domain_ids)  # uniform domain sampling\n            try:\n                imgs, labels, _ = next(iters[d])\n            except StopIteration:\n                iters[d] = iter(loaders_dict[d])\n                imgs, labels, _ = next(iters[d])\n\n        labels = smooth_labels(labels, LABEL_SMOOTH)\n\n        imgs = imgs.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n\n        if device.type == \"cuda\":\n            imgs = imgs.contiguous(memory_format=torch.channels_last)\n\n        with torch.amp.autocast(device_type=\"cuda\", enabled=(USE_AMP and device.type == \"cuda\")):\n            logits = model(imgs)\n            loss = criterion(logits, labels)\n            loss = loss / ACCUM_STEPS\n\n        if scaler is not None and (USE_AMP and device.type == \"cuda\"):\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n\n        if (step + 1) % ACCUM_STEPS == 0:\n            if scaler is not None and (USE_AMP and device.type == \"cuda\"):\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                optimizer.step()\n\n            optimizer.zero_grad(set_to_none=True)\n\n            if scheduler is not None:\n                scheduler.step()\n\n            if ema is not None:\n                ema.update(model)\n\n        losses.append(loss.item() * ACCUM_STEPS)\n        pbar.set_postfix({\"loss\": f\"{np.mean(losses[-20:]):.4f}\", \"lr\": f\"{optimizer.param_groups[0]['lr']:.2e}\"})\n\n    return {\n        \"loss\": float(np.mean(losses)),\n        \"mixup_ratio\": float(mix_ratio / max(1, epoch_steps))\n    }\n\n\n@torch.no_grad()\ndef validate(model, loader, criterion, device, thresholds=None, tta=False):\n    model.eval()\n    losses, all_probs, all_labels = [], [], []\n\n    for images, labels, _ in tqdm(loader, desc=\"Val\", leave=False):\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n        if device.type == \"cuda\":\n            images = images.contiguous(memory_format=torch.channels_last)\n\n        logits = model(images)\n        if tta:\n            logits2 = model(torch.flip(images, dims=[3]))\n            logits = (logits + logits2) / 2.0\n\n        loss = criterion(logits, labels)\n        losses.append(loss.item())\n\n        probs = torch.sigmoid(logits).cpu().numpy()\n        all_probs.append(probs)\n        all_labels.append(labels.cpu().numpy())\n\n    probs = np.vstack(all_probs)\n    labels = np.vstack(all_labels)\n    metrics = compute_metrics(labels, probs, thresholds)\n    metrics[\"loss\"] = float(np.mean(losses))\n    return metrics, probs, labels\n\n\ndef plot_training_curves(history, save_dir):\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    ep = range(1, len(history[\"train_loss\"]) + 1)\n\n    axes[0].plot(ep, history[\"train_loss\"], label=\"Train Loss\")\n    axes[0].plot(ep, history[\"val_loss\"], label=\"Val Loss\")\n    axes[0].legend(); axes[0].grid(True, alpha=0.3)\n    axes[0].set_title(\"Loss\")\n\n    axes[1].plot(ep, history[\"val_auc\"], label=\"Val mAUC\")\n    axes[1].legend(); axes[1].grid(True, alpha=0.3)\n    axes[1].set_ylim([0, 1.0])\n    axes[1].set_title(\"Val mAUC\")\n\n    os.makedirs(save_dir, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(f\"{save_dir}/training_curves.png\", dpi=250)\n    plt.close()\n\n\n# =============================================================================\n# MAIN\n# =============================================================================\n\nif __name__ == \"__main__\":\n    set_seed(SEED)\n    os.makedirs(SAVE_DIR, exist_ok=True)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Harmonize if missing\n    if not os.path.exists(\"/kaggle/working/harmonized_labels/ODIR_train.csv\"):\n        harmonized = harmonize_all_datasets()\n        save_harmonized_data(harmonized, output_dir=\"./harmonized_labels\")\n\n    print(\"=\" * 90)\n    print(f\"Mode: {'FAST' if FAST_MODE else 'HEAVY'} | IMG={IMG_SIZE} | BATCH={BATCH_SIZE} | ACCUM={ACCUM_STEPS} | AMP={USE_AMP}\")\n    print(f\"Train: {TRAIN_DOMAINS} | Test: {TEST_DOMAIN}\")\n    print(\"=\" * 90)\n\n    train_datasets = [RetinalDataset(p, i, transform=get_transforms(True)) for i, p in enumerate(TRAIN_CSVS)]\n    val_datasets = [RetinalDataset(p, i, transform=get_transforms(False)) for i, p in enumerate(VAL_CSVS)]\n    test_dataset = RetinalDataset(TEST_CSV, 999, transform=get_transforms(False))\n\n    pos_weights = calculate_pos_weights(train_datasets).to(device)\n\n    # loaders\n    g = torch.Generator().manual_seed(SEED)\n    train_loaders = {\n        i: DataLoader(\n            ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True,\n            num_workers=4, pin_memory=True,\n            persistent_workers=True, prefetch_factor=2,\n            generator=g\n        )\n        for i, ds in enumerate(train_datasets)\n    }\n\n    combined_val = ConcatDataset(val_datasets)\n    val_loader = DataLoader(combined_val, batch_size=BATCH_SIZE, shuffle=False,\n                            num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n                             num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n\n    # auto epoch steps (prevents wasting time)\n    # ODIR batches ~292, RFMiD_v2 batches ~21 -> using max makes sense\n    max_batches = max(len(dl) for dl in train_loaders.values())\n    epoch_steps = max_batches  # fast + consistent\n    print(f\"[INFO] epoch_steps (auto) = {epoch_steps}\")\n\n    # model\n    model = RetinaEffCNN(num_classes=8, width_mult=WIDTH_MULT, dropout=0.35, drop_path_rate=0.10).to(device)\n    if device.type == \"cuda\":\n        model = model.to(memory_format=torch.channels_last)\n\n    print(f\"[INFO] Trainable params: {count_parameters(model):,}\")\n\n    # loss/optim\n    criterion = AsymmetricLoss(\n        gamma_pos=ASL_GAMMA_POS, gamma_neg=ASL_GAMMA_NEG, clip=ASL_CLIP, pos_weight=pos_weights\n    )\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n    # CORRECT scheduler: steps only when optimizer updates\n    updates_per_epoch = int(np.ceil(epoch_steps / ACCUM_STEPS))\n    total_updates = EPOCHS * updates_per_epoch\n    warmup_updates = int(0.08 * total_updates)\n\n    def lr_lambda(u):\n        if u < warmup_updates:\n            return (u + 1) / max(1, warmup_updates)\n        progress = (u - warmup_updates) / max(1, (total_updates - warmup_updates))\n        return 0.5 * (1.0 + np.cos(np.pi * progress))\n\n    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n    scaler = torch.amp.GradScaler(\"cuda\", enabled=(USE_AMP and device.type == \"cuda\"))\n    ema = ModelEMA(model, decay=EMA_DECAY)\n\n    history = {\"train_loss\": [], \"val_loss\": [], \"val_auc\": []}\n    best_val_auc = 0.0\n    patience = 0\n\n    for epoch in range(EPOCHS):\n        train_metrics = train_epoch_mixup(\n            model, train_loaders, criterion, optimizer, device,\n            scaler=scaler if (USE_AMP and device.type == \"cuda\") else None,\n            ema=ema, scheduler=scheduler,\n            epoch_steps=epoch_steps\n        )\n\n        # validate with EMA\n        ema.apply_to(model)\n        val_metrics, _, _ = validate(model, val_loader, criterion, device, thresholds=None, tta=False)\n        ema.restore(model)\n\n        history[\"train_loss\"].append(train_metrics[\"loss\"])\n        history[\"val_loss\"].append(val_metrics[\"loss\"])\n        history[\"val_auc\"].append(val_metrics[\"mAUC\"])\n\n        print(f\"Epoch {epoch+1:02d} | TrainLoss {train_metrics['loss']:.4f} | \"\n              f\"Val mAUC {val_metrics['mAUC']:.4f} | Mix {train_metrics['mixup_ratio']:.1%} | \"\n              f\"LR {optimizer.param_groups[0]['lr']:.2e}\")\n\n        if val_metrics[\"mAUC\"] > best_val_auc:\n            best_val_auc = val_metrics[\"mAUC\"]\n            patience = 0\n            torch.save({\"model\": model.state_dict(), \"ema\": ema.shadow, \"best_val_auc\": best_val_auc},\n                       f\"{SAVE_DIR}/best_model.pth\")\n            print(f\"  âœ“ Saved best (EMA val mAUC={best_val_auc:.4f})\")\n        else:\n            patience += 1\n\n        if patience >= EARLY_STOP_PATIENCE:\n            print(f\"[INFO] Early stopping at epoch {epoch+1}\")\n            break\n\n    # load best\n    ckpt = torch.load(f\"{SAVE_DIR}/best_model.pth\", map_location=device)\n    model.load_state_dict(ckpt[\"model\"])\n    ema.shadow = ckpt[\"ema\"]\n    print(f\"\\n[INFO] Best Val mAUC (EMA): {ckpt['best_val_auc']:.4f}\")\n\n    # thresholds from val (EMA)\n    ema.apply_to(model)\n    _, val_probs, val_labels = validate(model, val_loader, criterion, device, thresholds=None, tta=False)\n    thresholds = find_optimal_thresholds(val_labels, val_probs)\n    ema.restore(model)\n\n    # test (EMA + optional TTA)\n    print(f\"\\n[INFO] Testing on {TEST_DOMAIN} (EMA{' + TTA' if USE_TTA_ON_TEST else ''})...\")\n    ema.apply_to(model)\n    test_metrics, _, _ = validate(model, test_loader, criterion, device, thresholds=thresholds, tta=USE_TTA_ON_TEST)\n    ema.restore(model)\n\n    print(\"\\n\" + \"=\" * 80)\n    print(f\"TEST RESULTS - {TEST_DOMAIN} (RetinaEffCNN)\")\n    print(\"=\" * 80)\n    print(f\"mAUC:     {test_metrics['mAUC']:.4f}\")\n    print(f\"mAP:      {test_metrics['mAP']:.4f}\")\n    print(f\"Macro F1: {test_metrics['macro_f1']:.4f}\")\n    print(\"=\" * 80)\n\n    plot_training_curves(history, SAVE_DIR)\n    print(f\"[INFO] Saved curves/results to: {SAVE_DIR}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T09:35:45.062019Z","iopub.execute_input":"2026-01-18T09:35:45.062461Z","iopub.status.idle":"2026-01-18T11:47:48.149763Z","shell.execute_reply.started":"2026-01-18T09:35:45.062439Z","shell.execute_reply":"2026-01-18T11:47:48.148765Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nHARMONIZING DATASETS\n============================================================\n\nProcessing train split...\nRFMiD_v2 train: Found 507, Skipped 2\n\nProcessing val split...\n\nProcessing test split...\nRFMiD_v2 test: Found 170, Skipped 4\n==========================================================================================\nMode: FAST | IMG=288 | BATCH=32 | ACCUM=1 | AMP=True\nTrain: ODIR + RFMiD_v2 | Test: RFMiD_v1\n==========================================================================================\n[INFO] Domain 0: Loaded 7000 images from ODIR_train.csv\n[INFO] Domain 1: Loaded 507 images from RFMiD_v2_train.csv\n[INFO] Domain 0: Loaded 1000 images from ODIR_val.csv\n[INFO] Domain 1: Loaded 177 images from RFMiD_v2_val.csv\n[INFO] Domain 999: Loaded 640 images from RFMiD_v1_test.csv\n\n[INFO] Positive class weights:\n  N: 2.08\n  D: 2.27\n  G: 15.65\n  C: 15.68\n  A: 21.54\n  H: 26.80\n  M: 19.02\n  O: 2.39\n[INFO] epoch_steps (auto) = 218\n[INFO] Trainable params: 2,015,618\n","output_type":"stream"},{"name":"stderr","text":"Train:   0%|          | 0/218 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | TrainLoss 0.9760 | Val mAUC 0.4867 | Mix 52.8% | LR 3.59e-04\n  âœ“ Saved best (EMA val mAUC=0.4867)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | TrainLoss 0.7985 | Val mAUC 0.5162 | Mix 53.2% | LR 7.16e-04\n  âœ“ Saved best (EMA val mAUC=0.5162)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | TrainLoss 0.6887 | Val mAUC 0.5196 | Mix 56.4% | LR 1.00e-03\n  âœ“ Saved best (EMA val mAUC=0.5196)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | TrainLoss 0.6639 | Val mAUC 0.5544 | Mix 56.0% | LR 9.97e-04\n  âœ“ Saved best (EMA val mAUC=0.5544)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | TrainLoss 0.6127 | Val mAUC 0.5602 | Mix 60.6% | LR 9.89e-04\n  âœ“ Saved best (EMA val mAUC=0.5602)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 06 | TrainLoss 0.6002 | Val mAUC 0.5532 | Mix 61.0% | LR 9.76e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 07 | TrainLoss 0.5656 | Val mAUC 0.5588 | Mix 56.0% | LR 9.59e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 08 | TrainLoss 0.5491 | Val mAUC 0.5253 | Mix 56.9% | LR 9.37e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 09 | TrainLoss 0.5291 | Val mAUC 0.5271 | Mix 54.6% | LR 9.11e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | TrainLoss 0.5337 | Val mAUC 0.4998 | Mix 57.8% | LR 8.82e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11 | TrainLoss 0.5072 | Val mAUC 0.5343 | Mix 51.8% | LR 8.48e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12 | TrainLoss 0.4774 | Val mAUC 0.5709 | Mix 52.3% | LR 8.12e-04\n  âœ“ Saved best (EMA val mAUC=0.5709)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13 | TrainLoss 0.4907 | Val mAUC 0.6054 | Mix 56.0% | LR 7.72e-04\n  âœ“ Saved best (EMA val mAUC=0.6054)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14 | TrainLoss 0.4912 | Val mAUC 0.6172 | Mix 51.8% | LR 7.30e-04\n  âœ“ Saved best (EMA val mAUC=0.6172)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15 | TrainLoss 0.4879 | Val mAUC 0.5746 | Mix 57.3% | LR 6.86e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16 | TrainLoss 0.4635 | Val mAUC 0.5670 | Mix 55.5% | LR 6.40e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17 | TrainLoss 0.4654 | Val mAUC 0.5295 | Mix 53.2% | LR 5.92e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18 | TrainLoss 0.4464 | Val mAUC 0.5839 | Mix 54.6% | LR 5.44e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19 | TrainLoss 0.4377 | Val mAUC 0.6389 | Mix 66.1% | LR 4.95e-04\n  âœ“ Saved best (EMA val mAUC=0.6389)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20 | TrainLoss 0.4485 | Val mAUC 0.6543 | Mix 63.8% | LR 4.46e-04\n  âœ“ Saved best (EMA val mAUC=0.6543)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21 | TrainLoss 0.4163 | Val mAUC 0.6889 | Mix 54.6% | LR 3.98e-04\n  âœ“ Saved best (EMA val mAUC=0.6889)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22 | TrainLoss 0.4349 | Val mAUC 0.6745 | Mix 53.7% | LR 3.51e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23 | TrainLoss 0.4054 | Val mAUC 0.6946 | Mix 48.6% | LR 3.05e-04\n  âœ“ Saved best (EMA val mAUC=0.6946)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24 | TrainLoss 0.4147 | Val mAUC 0.7017 | Mix 56.0% | LR 2.61e-04\n  âœ“ Saved best (EMA val mAUC=0.7017)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25 | TrainLoss 0.4289 | Val mAUC 0.7297 | Mix 60.1% | LR 2.20e-04\n  âœ“ Saved best (EMA val mAUC=0.7297)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26 | TrainLoss 0.4070 | Val mAUC 0.7208 | Mix 54.6% | LR 1.81e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27 | TrainLoss 0.3834 | Val mAUC 0.7237 | Mix 54.6% | LR 1.45e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28 | TrainLoss 0.3721 | Val mAUC 0.7198 | Mix 56.9% | LR 1.12e-04\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29 | TrainLoss 0.3829 | Val mAUC 0.7271 | Mix 57.3% | LR 8.32e-05\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30 | TrainLoss 0.3973 | Val mAUC 0.7477 | Mix 55.5% | LR 5.83e-05\n  âœ“ Saved best (EMA val mAUC=0.7477)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31 | TrainLoss 0.3996 | Val mAUC 0.7467 | Mix 59.2% | LR 3.76e-05\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32 | TrainLoss 0.3925 | Val mAUC 0.7365 | Mix 59.6% | LR 2.13e-05\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33 | TrainLoss 0.3666 | Val mAUC 0.7225 | Mix 56.9% | LR 9.49e-06\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34 | TrainLoss 0.4096 | Val mAUC 0.7502 | Mix 49.5% | LR 2.38e-06\n  âœ“ Saved best (EMA val mAUC=0.7502)\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35 | TrainLoss 0.3928 | Val mAUC 0.7575 | Mix 47.7% | LR 0.00e+00\n  âœ“ Saved best (EMA val mAUC=0.7575)\n\n[INFO] Best Val mAUC (EMA): 0.7575\n","output_type":"stream"},{"name":"stderr","text":"                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n[INFO] Testing on RFMiD_v1 (EMA)...\n","output_type":"stream"},{"name":"stderr","text":"                                                    \r","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nTEST RESULTS - RFMiD_v1 (RetinaEffCNN)\n================================================================================\nmAUC:     0.7433\nmAP:      0.3917\nMacro F1: 0.3261\n================================================================================\n[INFO] Saved curves/results to: ./results_lodo_mixup/retinaeffcnn_fast\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}